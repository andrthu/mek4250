\documentclass[11pt,a4paper]{article}
\usepackage{amsmath,amsfonts,amssymb,amsthm, gensymb}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{color, array, threeparttable}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
 
\usepackage{cite}

\usepackage[ruled]{algorithm2e}


\usepackage{listings}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}
\DeclareMathAlphabet{\mathbbold}{U}{bbold}{m}{n}    

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}


\usepackage{graphicx}

%\cite{maday2002parareal}
% 4.3 \ref{algebraic_sec}
\begin{document}
\section{definition}
\begin{definition}[Fine and coarse propagator]
Let $f(u(t),t)=0$ be a time dependent differential equation. Given $\Delta T$ and an initial condition $\omega$, let $u_f$ and $u_c$ be a fine and a coarse numerical solution of the initial value problem:
\begin{align}
 \left\{
     \begin{array}{lr}
		f(u(t),t)=0 \ \quad \textrm{For $t \in (0,\Delta T)$} \\
		u(0)=\omega
	\end{array}
	\right.	
\end{align}
We then define the fine propagator as $\bold F_{\Delta T}(\omega) = u_f(\Delta T)$ and the coarse propagator as $\bold G_{\Delta T}(\omega) = u_c(\Delta T)$.
\end{definition}
\section{PPC}
\subsection{Virtual problem} \label{vir_sec}
The Parareal-based preconditioner only affects the part of the gradient connected to the virtual control $\Lambda$. To motivate and derive $Q$, we therefore consider an optimal control problem where the real control $v$ is removed, and the objective function only depends on $\Lambda$. We have already presented this problem in section \ref{algebraic_sec}, but we restate it here for future reference. However, before we do this let us first properly define the fine coarse propagators.
\begin{definition}[Fine and coarse propagator]
Let $f(y(t),t)=0$ be a time dependent differential equation. Given $\Delta T$ and an initial condition $\omega$, let $y_f$ and $y_c$ be a fine and a coarse numerical solution of the initial value problem:
\begin{align}
 \left\{
     \begin{array}{lr}
		f(y(t),t)=0 \ \quad \textrm{For $t \in (0,\Delta T)$} \\
		y(0)=\omega
	\end{array}
	\right.	
\end{align}
We then define the fine propagator as $\bold F_{\Delta T}(\omega) = y_f(\Delta T)$ and the coarse propagator as $\bold G_{\Delta T}(\omega) = y_c(\Delta T)$.
\end{definition}
We then use the fine propagator $\bold F_{\Delta T}(\omega)$ to define the virtual problem.
\begin{definition}[Virtual problem]
Given a fine propagator $\bold F_{\Delta T}$, that solves a time dependent differential equation $f(y(t),t)=0$, an initial condition $\lambda_0=y_0$ and the control variable $\Lambda=(\lambda_1,...,\lambda_ {N-1})$, the virtual control problem is defined as follows:
\begin{align}
&\min_{\Lambda}\bold{J}(\Lambda,y) = \sum_{i=1}^{N-1} (y_{i-1}(T_{i})-\lambda_{i})^2 \label{virtual_func} \\
&\textrm{Subject to } \ y_{i-1}(T_{i}) = \bold F_{\Delta T}(\lambda_{i-1}) \ i=1,...,N-1 \label{virtual}
\end{align}
\end{definition}
In chapter \ref{parareal_chap} we explained how the virtual problem could be solved by setting $\lambda_i= \bold F_{\Delta T}(\lambda_{i-1})$, which is the same as solving $\bold J(\Lambda,y)=0$. This equation could be written up on matrix form as:
\begin{align*}
  \left[ \begin{array}{cccc}
   \mathbbold{1} & 0 & \cdots & 0 \\  
   -\bold{F}_{\Delta T} & \mathbbold{1} & 0 & \cdots \\ 
   0 &-\bold{F}_{\Delta T} & \mathbbold{1}  & \cdots \\
   0 &\cdots &-\bold{F}_{\Delta T} & \mathbbold{1}  \\
   \end{array}  \right] 
   \left[ \begin{array}{c}
   \lambda_1 \\
   \lambda_2 \\
   \cdots \\
   \lambda_{N-1} \\
   \end{array}  \right] =
   \left[ \begin{array}{c}
   \bold F_{\Delta T}( y_0) \\
   0 \\
   \cdots \\
   0 \\
   \end{array}  \right].
\end{align*}
Letting $M\in\mathbb{R}^{N-1\times N-1}$ and $H\in\mathbb{R}^{N-1}$ represent the matrix and right hand side of the above expression makes us able to rewrite $\bold J(\Lambda,y)=0$ compactly as:
\begin{align}
M \ \Lambda = H. \label{Parareal_equation}
\end{align}
In section \ref{algebraic_sec} we explained how the Parareal algorithm could be reformulated as preconditioned fix point iteration solving equation (\ref{Parareal_equation}), expressed as follows:
\begin{align}
\Lambda^{k+1} = \Lambda^k + \bar{M}^{-1}(H-M\Lambda^k)\label{par_mat_sys}
\end{align}
Where $\bar{M}$ is the coarse version of the matrix $M$, meaning:
\begin{align*}
\bar{M} = \left[ \begin{array}{cccc}
   \mathbbold{1} & 0 & \cdots & 0 \\  
   -\bold{G}_{\Delta T} & \mathbbold{1} & 0 & \cdots \\ 
   0 &-\bold{G}_{\Delta T} & \mathbbold{1}  & \cdots \\
   0 &\cdots &-\bold{G}_{\Delta T} & \mathbbold{1}   \\
   \end{array}  \right]\in\mathbb{R}^{N-1\times N-1}.
\end{align*}
When we are solving the original optimal control problem we do not try to find $(v,\Lambda,y)$ that solves $J_{\mu}(v,\Lambda,y)=0$. Instead we try to solve $\hat J_{\mu}'(v,\Lambda)=0$. To find the Parareal-based preconditioner, we therefore try to find a similar expression to (\ref{Parareal_equation}) for $\bold{\hat{J}}'(\Lambda)=0$. To state this exprssion, we first need to define the coarse and fine adjoint propagators.
\begin{definition}[Fine and coarse adjoint propagator] \label{adjoint_prop_def}
Let $f(y(t),t)=0$ be a time dependent differential equation. Given $\Delta T$ a state $y(t)$ and an initial condition $\omega$, let $p_f$ and $p_c$ be a fine and a coarse numerical solution of the initial value problem:
\begin{align}
 \left\{
     \begin{array}{lr}
		f'(y(t),t)^*p(t)=0 \ \quad \textrm{For $t \in (0,\Delta T)$} \\
		p(\Delta T)=\omega
	\end{array}
	\right.	
\end{align}
We then define the fine adjoint propagator as $\bold F_{\Delta T}^*(\omega) = p_f(0)$ and the coarse adjoint propagator as $\bold G_{\Delta T}^*(\omega) = p_c(0)$. We also define adjoint versions of the matrices $M$ and $\bar M$ as: 
\begin{align*}
M^*= \left[ \begin{array}{cccc}
   \mathbbold{1} & -\bold{F}_{\Delta T}^* & 0 & 0 \\  
   0 & \mathbbold{1} & -\bold{F}_{\Delta T}^* & \cdots \\ 
   \cdots &0 &  \mathbbold{1} & -\bold{F}_{\Delta T}^* \\
   0 &\cdots &\cdots &  \mathbbold{1}  \\
   \end{array}  \right],
\bar M^*= \left[ \begin{array}{cccc}
   \mathbbold{1} & -\bold{G}_{\Delta T}^* & 0 & 0 \\  
   0 & \mathbbold{1} & -\bold{G}_{\Delta T}^* & \cdots \\ 
   \cdots &0 &  \mathbbold{1} & -\bold{G}_{\Delta T}^* \\
   0 &\cdots &\cdots &  \mathbbold{1}  \\
   \end{array}  \right].
\end{align*}
\end{definition} 
Using the matrices from definition \ref{adjoint_prop_def} we can write up the following proposition concerning the gradient of the reduced objective function of the virtual problem.
\begin{proposition} \label{vir_grad_prop}
The reduced objective function of the virtual problem (\ref{virtual_func}-\ref{virtual}) is:
\begin{align}
\bold{\hat J}(\Lambda) = \sum_{i=1}^{N-1} (\bold F_{\Delta T}(\lambda_{i-1})-\lambda_{i})^2.\label{reduced_viritual}
\end{align}
Solving $\bold{\hat J}'(\Lambda)=0$ is equivalent to resolving the system:
\begin{align}
M^* \ M \ \Lambda \ = \ M^* \ H. \label{vir_grad_sys}
\end{align}
A preconditioned fix point iteration for equation (\ref{vir_grad_sys}) inspired by the Parareal formulation (\ref{par_mat_sys}) is therefore:
\begin{align}
\Lambda^{k+1} = \Lambda^k + \bar{M}^{-1}\bar M^{-*}(M^*H-M^*M\Lambda^k). \label{grad_fix_iter}
\end{align}
\end{proposition}
\begin{proof}
Luckily for us we have already derived the gradient of $\bold{\hat J}$ in (\ref{penalty grad}). There we stated the gradient for the penalized version of the example problem (\ref{exs_J}-\ref{exs_E}). If we ignore the part this gradient related to the real control $v$, we find get the following expression for $\bold{\hat J}'$:
\begin{align*}
\hat{\bold J}'(\Lambda) = \{p_{i+1}(T_i)-p_{i}(T_i)\}_{i=1}^{N-1}.
\end{align*}
Here $p_i$ refers to the decomposed adjoint equation on interval $[T_{i-1},T_{i}]$. We now want to show that setting $p_{i+1}(T_i)-p_{i}(T_i)=0$ for $i=1,...,N-1$ is equivalent to equation \ref{vir_grad_sys}. To this we will simply write out the expression $M^*(M\Lambda-H)$ starting with $M\Lambda-H$.
\begin{align*}
M \ \Lambda - H  = \left( \begin{array}{c}
	\lambda_1-\bold{F}_{\Delta T}(\lambda_0)\\
	\lambda_2-\bold{F}_{\Delta T}(\lambda_1) \\
	\cdots \\
	\lambda_{N-1}-\bold{F}_{\Delta T}(\lambda_{N-1}) 
	\end{array} \right).
\end{align*}
Notice that $\bold{F}_{\Delta T}(\lambda_{i-1})-\lambda_i$ is the initial condition of $i$-th adjoint equation, i.e. $p_i(T_i)=\bold{F}_{\Delta T}(\lambda_{i-1})-\lambda_i$. By exploiting this, and multiplying $M\Lambda-H$ with $M^*$ we get:
\begin{align}
M^* (M \ \Lambda-H)&=
	\left( \begin{array}{c}
	 \bold{F}_{\Delta T}^*(p_2( T_2))-p_1(T_1)\\
	\bold{F}_{\Delta T}^*(p_3( T_3))-p_2(T_2)\\
	\cdots \\
	-p_{N-1}(T_{N-1})
	\end{array} \right)
	\\
	&=\left( \begin{array}{c}
	p_2(T_1)-p_1(T_1)\\
	p_3(T_2)-p_2(T_2)\\
	\cdots \\
	p_{N-1}(T_{N-2})-p_{N-2}(T_{N-2}) \\
	-p_{N-1}(T_{N-1})
	\end{array} \right).
\end{align}
The last step is done by using $p_i(T_{i-1})=-F_{\Delta T}^*(-p_i(T_i))$, and this is possible since the adjoint equation is always linear. We see that that the $i$-th component of $M^* (M \Lambda-H)$ is equal to $p_{i+1}(T_i)-p_{i}(T_i)$ for $i\neq N-1$. The last component of $M^* (M \Lambda-H)$ is $-p_{N-1}(T_{N-1})$, and we are therefore missing $p_N(T_{N-1})$. This is however unproblematic since in context of the the virtual problem $p_N(T_{N-1})=0$. This shows us that $\hat{\bold J}'(\Lambda)= M^* (M \Lambda-H)$, which means that $\hat{\bold J}'(\Lambda)=0 \iff M^*M\Lambda =M^*H$. Since $\bar M$ and $\bar M^*$ approximates $M$ and $M^*$, $\bar{M}^{-1}\bar M^{-*}$ would be a natural preconditioner for a fix point iteration solving $M^*M\Lambda =M^*H$. 
\end{proof}
Proposition \ref{vir_grad_prop} motivates $Q_{\Lambda}=\bar{M}^{-1}\bar M^{-*}$ as a preconditioner for the solution of decomposed and penalized optimal control problems, and this is actually the Parareal-based preconditioner proposed in \cite{maday2002parareal}. Inserting $Q_{\Lambda}$ into $Q$ yields the following:
\begin{align}
Q = \left[ \begin{array}{cc}
	\mathbbold{1} & 0 \\
	0 &  \bar{M}^{-1}\bar{M}^{-*}\\
	\end{array} \right]. \label{Q_PC}
\end{align}  
In \cite{maday2002parareal} $Q$ is proposed as preconditioner for a steepest descent method. We do however not know if $Q$ is positive definite, or if is in any shape or form related to the Hessian of the objective function. We will investigate these questions further by reformulating the reduced objective function (\ref{reduced_viritual}) for the virtual problem to a least squares problem.
\subsection{Virtual lest squares problem}
Looking at the equation $M^*M\Lambda =M^*H$ we recognize the normal equation, which is connected to linear least squares problems. We therefore suspect that the virtual problem can be reformulated as a least squares problem. It turns out that this is indeed the case. Before we can write up the new formulation, we need to define the vector function  $:\mathbb{R}^{N-1}\rightarrow \mathbb{R}^{N-1}$ as:
\begin{align}
x(\Lambda)= \left( \begin{array}{c}  
   \lambda_1 - \bold F_{\Delta T}(\lambda_0) \\ 
   \lambda_2 - \bold F_{\Delta T}(\lambda_1) \\
   \cdots  \\
   \lambda_{N-1} -\bold F_{\Delta T}(\lambda_{N-1}) \\
   \end{array}  \right).
\end{align}
This makes us able to write up the virtual least squares problem:
\begin{align}
\min_{\Lambda\in\mathbb{R}^{N-1}}\hat{\bold J}(\Lambda) = x(\Lambda)^Tx(\Lambda)  \label{non_lin_LS}
\end{align} 
We now write up the Hessian $\nabla^2 \hat{\bold J}(\Lambda)$ of $\bold{\hat J}$ from (\ref{non_lin_LS}) in proposition \ref{NonLin_prop}. 
\begin{proposition}\label{NonLin_prop}
The Hessian of function (\ref{non_lin_LS}) is
\begin{align*}
\nabla^2 \hat{\bold J}(\Lambda) &= 2\nabla x^T\nabla x + 2\sum_{i=1}^{N-1} \nabla^2 x_i(\Lambda) x_i(\Lambda)\\
&=2M(\Lambda)^TM(\Lambda) + 2D(\Lambda)
\end{align*}
Here $D(\Lambda)$ is a diagonal matrix with diagonal entries 
\begin{align*}
D_i=-\bold{F}_{\Delta T}''(\lambda_i)(\lambda_{i+1}-\bold F_{\Delta T}(\lambda_i)) \quad i=1,...,N-1,
\end{align*}
while $M(\Lambda)$ is the linearised forward model:
\begin{align*}
M(\Lambda) &= \left[ \begin{array}{cccc}
   \mathbbold{1} & 0 & \cdots & 0 \\  
   -\bold{F}_{\Delta T}'(\lambda_{1}) & \mathbbold{1} & 0 & \cdots \\ 
   0 &-\bold{F}_{\Delta T}'(\lambda_{2}) & \mathbbold{1}  & \cdots \\
   0 &\cdots &-\bold{F}_{\Delta T}'(\lambda_{N-1}) & \mathbbold{1}  \\
   \end{array}  \right]
\end{align*}	
\end{proposition}
\begin{proof}
We start by differentiating $\hat{\bold J}$:
\begin{align*}
\nabla \hat{\bold J}(\Lambda) &= 2 \nabla x(\Lambda)^T x(\Lambda)\\
&=2\sum_{i=1}^{N-1} \nabla x_i(\Lambda) x_i(\Lambda)
\end{align*}
If we now differentiate $\nabla \hat{\bold J}$, we get:
\begin{align*}
\nabla^2 \hat{\bold J}(\Lambda) &= 2\nabla x^T\nabla x + 2\sum_{i=1}^{N-1} \nabla^2 x_i(\Lambda) x_i(\Lambda)
\end{align*}
We see that $\nabla x(\Lambda)=M(\Lambda)$, by looking at $\frac{\partial x_i}{\partial \lambda_j}$
\begin{align*}
\frac{\partial x_i}{\partial \lambda_j} = \left\{
     \begin{array}{lr}
		1 \quad\quad\quad\quad\quad i=j\\
		-\bold F_{\Delta T}'(\lambda_{j}) \quad i>1 \wedge j=i-1 \\
		0 \quad\quad\quad\quad\quad i\neq j \vee j\neq i-1
	\end{array}
   \right.	
\end{align*}
We can similarly find $\nabla^2 x_i$ by differentiating $x$ twice:
\begin{align*}
\frac{\partial^2 x_i}{\partial \lambda_j\partial\lambda_k} = \left\{
     \begin{array}{lr}
		-\bold F_{\Delta T}''(\lambda_{j}) \quad i>1 \wedge j=k=i-1 \\
		0 \quad\textrm{in all other cases}
	\end{array}
   \right.	
\end{align*}
Now summing up the terms $\nabla^2 x_i(\Lambda)x_i(\Lambda)$ would yield the diagonal matrix $D(\Lambda)$ described in proposition \ref{NonLin_prop}.
\end{proof}
\noindent
As we have seen the Hessian of the non-linear problem consists of two parts. One is the linearised forward model multiplied with its adjoint, while the second part is a diagonal matrix related to the second derivative of the propagator $\bold F_{\Delta T}$, and the residuals $\lambda_i-\bold F_{\Delta T}$. The first part of $\nabla^2 \bold{\hat{J}}$ is analogue to the Hessian of the linear problem. It is symmetric positive definite, and taking its inverse corresponds to first applying the backwards model, and then the forward model. What makes the Hessian of the non-linear problematic is therefore its second term. The first issue with the diagonal matrix $D(\Lambda)$, is how to calculate $\bold F_{\Delta T}''$. Another issue is that we can not guarantee that the sum of $M(\Lambda)^TM(\Lambda)$ and $D(\Lambda)$ is a positive matrix, and the same problem would arise in a coarse approximation of $\nabla^2 \bold{\hat{J}}$. The lack of positivity is a problem since we want to use the coarse approximation as an initial inverted Hessian approximation in the BFGS-algorithm.
\\
\\
A way to get around the $D(\Lambda)$ term in the Hessian for non-linearly constrained problem, is simply to ignore it. This leaves us with the $M(\Lambda)^TM(\Lambda)$ term, which we know how to deal with. Ignoring the term depending on the second derivative and the residual is actually a known strategy for for solving non-linear least square problems. Details can be found in \cite{nocedal2006numerical}. A justification for this approach, is that at least in instances where we are close to a solution, the $\lambda_i-\bold F_{\Delta T}$ terms will be close to zero, and the $M(\Lambda)^TM(\Lambda)$ term will therefore dominate the Hessian. Ignoring the $D(\Lambda)$ term means that we can define an inverse Hessian approximation based on a coarse propagator $\bold G_{\Delta T}$ in the same way as we did for the problem with linear state equation constraints. This means that we define a matrix $\bar M(\Lambda)$:
\begin{align*}
\bar M(\Lambda) &= \left[ \begin{array}{cccc}
   \mathbbold{1} & 0 & \cdots & 0 \\  
   -\bold{G}_{\Delta T}'(\lambda_{1}) & \mathbbold{1} & 0 & \cdots \\ 
   0 &-\bold{G}_{\Delta T}'(\lambda_{2}) & \mathbbold{1}  & \cdots \\
   0 &\cdots &-\bold{G}_{\Delta T}'(\lambda_{N-1}) & \mathbbold{1}  \\
   \end{array}  \right]
\end{align*}
The term $\bar{M}(\Lambda)^{-1}\bar{M}(\Lambda)^{-*}$ can then be used in an approximation of the inverse Hessian, as detailed in section \ref{vir_sec}.
\end{document}