\chapter{Parallel in time ODE solver methods} \label{parareal_chap}
The process of resolving time dependent differential equation in temporal direction, is an exercise which one would intuitively think is unsuited for parallelization. This is due to the simple fact that the solution of such equation at every time $T$ depends on the solution at times $t<T$, and it is therefore very difficult to partition the solution process into independent tasks that can be run in parallel. However the so called Parareal scheme introduced by Lions, Maday and Turinici in \cite{lions2001resolution} makes it possible to parallelize the numerical solution of differential equations in time. Before I describe Parareal, I will introduce an example equation and decompose it together with the time interval.
\section{Decomposing the time interval}
The Parareal scheme is used to parallelize differential equations in temporal direction, by decomposing the time interval $I=[0,T]$. An example of a time dependent differential equation that on this interval is:
\begin{align}
\left\{
   	\begin{array}{lr}
		\frac{\partial u}{\partial t} + Au = f \ \quad \textrm{For $t \in I$} \\
		u(0)=u_0
	\end{array}
   \right. \label{unbroken}
\end{align} 
Decomposing the interval $I$ means dividing the interval into $N$ subintervals $\{I_n = [T^{n},T^{n+1}]\}_{n=0}^{N-1}$, with length $\Delta T = T/N$. We define new equations for each interval:
\begin{align}
\left\{
     \begin{array}{lr}
		\frac{\partial u^n}{\partial t} + Au^n = f \ \quad \textrm{For $t \in I^n$} \\
		u^n(T^n)=\lambda^n
	\end{array}
	\right.	\label{broken}
\end{align}
Here $\lambda^0=u_0$. If $\Lambda=(\lambda_0,..,\lambda_{N-1})$ are known values, we can solve the equations independently on each interval. The problem is that the $\lambda$s depend on the previous intervals, and need to be calculated by solving the equation. The Parareal scheme is a way of getting around this.
\section{Parareal}\label{Parareal_sec}
We see that when we decompose the time domain, the original initial value problem (\ref{unbroken}) brakes down to a system of initial value problems of size $N$ (\ref{broken}). The idea of \cite{baffico2002parallel} is then first to define a fine solution operator $\bold F_{\Delta T}$, which given an initial condition $\lambda_i$ at time $T_i$, evolves $\lambda_i$, using a fine scheme applied to the $i$th equation (\ref{broken}), from time $T_i$ to $T_{i+1}$. Meaning:
\begin{align*}
\hat \lambda_{i+1}= u^i(T_{i+1})=\bold F_{\Delta T}(\lambda_i)
\end{align*} 
We name $\bold F_{\Delta T}$ the fine propagator, and note that letting $\hat \lambda_{1}=\bold F_{\Delta T}(u_0)$, and then applying $\bold F_{\Delta T}$ sequentially to $\hat \lambda_{i}$, is the same as solving (\ref{unbroken}), using the underlying numerical method of the fine propagator. However, we intend to use $\bold F_{\Delta T}$ simultaneously on a given set of initial values $\Lambda=(\lambda_0=u_0,\lambda_1,...,\lambda_{N-1})$, and not sequentially. Since we also want $\hat{\lambda_i}$ to be as close as possible to $\lambda_i$ for $i=1,...,N-1$, we define a coarse propagator $\bold G_{\Delta T}$, and use this operator to predict the $\Lambda$ values. The predictions are made by sequentially applying the coarse propagator to the system (\ref{broken}). This means:
\begin{align}
\lambda_i^0 &= \bold G_{\Delta T}(\lambda_{i-1}^0),\quad i=1,...,N-1 \\
\lambda_0^0&=u_0
\end{align} 
Once we have these predicted initial values, we can apply the fine propagator on all the equations in system (\ref{broken}) simultaneously, and then use the difference between our fine solution  and coarse solution $\delta_{i-1}^0= \bold F_ {\Delta T}( \lambda_{i-1}^0)-\bold G_ {\Delta T}( \lambda_{i-1}^0)$ at time $T_i$ to correct $\lambda_i^0$. The correction for time $T_i$, is done by using the coarse propagator on the already corrected $\lambda_{i-1}^1$, and then add the difference $\delta_{i-1}^0$ to $\bold G_ {\Delta T}(\lambda_{i-1}^1)$. When this sequential process is done, we have a new set of initial conditions $\lambda_i^1$, $i=1,...,N-1$, which means that we can redo the correction, and the prediction-correction formulation of Parareal can then be written up as the following iteration:
\begin{align}
\lambda_{i}^{k+1} &= \bold G_ {\Delta T}(\lambda_{i-1}^{k+1})+\bold F_ {\Delta T}( \lambda_{i-1}^{k})-\bold G_ {\Delta T}( \lambda_{i-1}^{k}), \quad i=1,...,N-1 \label{pred_corr_PR} \\
\lambda_0^k &= u_0
\end{align}
Updating our initial conditions $\Lambda^k$ from iteration $k$ to iteration $k+1$, requires $N$ fine propagations, which we can do in parallel, and $N$ coarse propagations, whet we need to do sequentially. We can now write up a simple algorithm for doing $K$ steps of Parareal.
\begin{align*}
1:\quad&\textrm{$\bold{Set}$ $\lambda_0^0=u_0$} \\
2:\quad&\textrm{$\bold{for}$ $i=1,...,N-1$:} \\
&\quad\bold{Set} \ \lambda_i^0=\bold G_ {\Delta T}(\lambda_{i-1}^0) \\
3:\quad&\textrm{$\bold{for}$ $k=1,...,K$:} \\
&\quad\textrm{$\bold{Set}$ $\lambda_0^k=u_0$} \\
&\quad\textrm{$\bold{Do}$ $\hat \lambda_i^k=\bold F_ {\Delta T}( \lambda_{i-1}^{k-1})$ in parallel} \\
&\quad\textrm{$\bold{for}$ $i=1,...,N-1$:} \\
&\quad \quad \quad \bold{Set} \ \lambda_{i}^{k} = \bold G_ {\Delta T}(\lambda_{i-1}^{k})+\hat\lambda_i^{k-1}-\lambda_i^{k-1}
\end{align*}
In the above algorithm we do $K$ iterations, where $K$ is a pre-chosen number. If one wanted to construct an actual Parareal algorithm, the iteration should instead terminate, when a certain stopping criteria is met. In general we want the iteration to stop when the Parareal solution is sufficiently close to the sequential solution. 
\section{Algebraic formulation}
In \cite{maday2002parareal} an algebraic reformulation of (\ref{pred_corr_PR}) is presented. The setting in \cite{maday2002parareal} is slightly different than the one we had in section \ref{Parareal_sec}, since they are trying to solve an optimal control problem with differential equation constraints, rather than to just solve a differential equation. Luckily for us the problem they are looking at is very much connected to that of solving the time decomposed differential equation system. The problem they solve follows below:
\begin{align*}
&\min_{\Lambda}\hat{J}(\Lambda) = \sum_{i=1}^{N-1} ||u^{i}(T_{i})-\lambda_{i}||^2 \\
&\textrm{Subject to } \ u^{i}(T_{i}) = \bold F_{\Delta T}(\lambda_{i-1}) \ i=1,...,N
\end{align*}
In the above optimal control problem the $\bold F_{\Delta T}$ is the fine propagator from the previous section, and $u$ and $\Lambda$ is also as defined in section \ref{Parareal_sec}. What we immediately notice, is that we can find the solution of the above problem by setting $J(\Lambda)=0$, which gives us the solution $\lambda_{i}=\bold  u^{i}(T_{i})=F_{\Delta T}(\lambda_{i-1})$. The authors of \cite{maday2002parareal} then write this system on matrix form as:
\begin{align}
  \left[ \begin{array}{cccc}
   \mathbbold{1} & 0 & \cdots & 0 \\  
   -\bold{F}_{\Delta T} & \mathbbold{1} & 0 & \cdots \\ 
   0 &-\bold{F}_{\Delta T} & \mathbbold{1}  & \cdots \\
   0 &\cdots &-\bold{F}_{\Delta T} & \mathbbold{1}  \\
   \end{array}  \right] 
   \left[ \begin{array}{c}
   \lambda_0 \\
   \lambda_1 \\
   \cdots \\
   \lambda_{N-1} \\
   \end{array}  \right] =
   \left[ \begin{array}{c}
   y^0 \\
   0 \\
   \cdots \\
   0 \\
   \end{array}  \right] \label{vir_mat_form_sys }
\end{align}
Or with notation:
\begin{align}
M \ \Lambda \ = \ H.\quad \textrm{With $M\in\mathbb{R}^{N\times N},H\in\mathbb{R}^N$ given by (\ref{vir_mat_form_sys }).} \label{vir_mat_sys}
\end{align}
We can solve system (\ref{vir_mat_form_sys }) by sequentially applying the fine propagator, but we again want to use the coarse propagator, so that we can run the fine propagator in parallel. We first define the coarse equivalent to $M$ as:
\begin{align}
\bar{M} = \left[ \begin{array}{cccc}
   \mathbbold{1} & 0 & \cdots & 0 \\  
   -\bold{G}_{\Delta T} & \mathbbold{1} & 0 & \cdots \\ 
   0 &-\bold{G}_{\Delta T} & \mathbbold{1}  & \cdots \\
   0 &\cdots &-\bold{G}_{\Delta T} & \mathbbold{1}   \\
   \end{array}  \right]
\end{align}
Using $\bar{M}$, we can write up what turns out to be the Parareal iteration (\ref{pred_corr_PR}) in Matrix notation:
\begin{align}
\Lambda^{k+1} = \Lambda^k + \bar{M}^{-1}(H-M\Lambda^k) \label{matrix_iter1}
\end{align}
Looking at the (\ref{matrix_iter1}), we recognise the Parareal iteration as a preconditioned fix point iteration, where $\bar{M}^-1$ is the prconditioner.
\section{Properties of Parareal}
\subsection{Error estimates}
According to \cite{lions2001resolution} we have the following error estimate for the Parareal scheme of (\ref{ODE_eks}):
\begin{gather*}
\forall \ n,0\leq n\leq N-1 \\ |Y_k^n-y(T^n)| + \max_{t\in[T^N,T^{n+1}]}|y_k^n(t)-y(t)| \leq c_k\Delta T^k
\end{gather*} 
This suggest that the max norm difference between exact and Parareal solution looks like this:
\begin{align*}
\max_{t\in[0,T]}|y_k(t)-y(t)| \leq C_k\Delta T^k
\end{align*}
The error estimate for a first order scheme, like implicit Euler, we know looks like this:
\begin{align*}
\max_{t\in[0,T]}|y_{\Delta t}(t)-y(t)| \leq C\Delta t
\end{align*}
It would then be reasonable that the number of iterations for the Parareal scheme needed to reach the same error as the fine first order solver, would be:
\begin{align*}
k\approx\frac{\log(\Delta t)}{\log(\Delta T)}
\end{align*}
This assumes that the constants $C_k$ and $C$ are similar. This is a reasonable assumption, since these constants depend on the parameters of the equation (\ref{ODE_eks}). 
\\
\\
To illustrate this lets try to solve a version of (\ref{ODE_eks}) using an implicit Euler scheme and Parareal with a fine implicit Euler solver. I will use  the parameters $a=1.3$, $T=1$ and $y_0= 3.52$. The fine resolution will be held constant at $\Delta t=\frac{1}{10000}$. I then calculated how many propagation iterations I needed to reduce the max-norm error to below $\Delta t$ for different time interval decompositions $N$. Table follows below:
 \begin{center}
    \begin{tabular}{| l | l | l | l |}
    \hline
     & $\frac{\log(\Delta t)}{\log(\Delta T)}$&iterations  & $\max_{t\in[0,T]}|y_k(t)-y(t)|$   \\ \hline
    $N=1$ &0 & 1& 8.416625e-5 	\\ \hline
    $N=2$ &13.3 &2& 8.416625e-5 	\\ \hline
    $N=5$ &5.7&4& 8.416625e-5	\\ \hline
    $N=10$ &4&4& 8.399513e-5	\\ \hline
    $N=25$ &2.8&3& 	8.737827e-5\\ \hline
    $N=100$ &2&2&	6.302522e-5\\ \hline
    \end{tabular}
\end{center}
Notice that for two intervals, the expected number of iterations is $13$, however with $N=2$, we get the same error as the one interval solution in only two iterations. The reason for this, is that doing $N$ iterations of the Parareal scheme when using $N$ time decompositions, is the same as solving the equation without any decompositions. 
