\chapter{Literature review}
The Parareal algorithm was introduced by Lions, Maday and Turinici in \cite{lions2001resolution} as a way to solve differential evolution equations $f(y(t),t)=0$ in parallel. This is done by combining a coarse and fine scheme for discretization in time. To introduce parallelism we first decompose the time domain $I=[0,T]$ into $N$ subintervals $I_i=[T_{i-1},T_i]$. This gives us $N$ equations $f_i(y_i(t),t)=0$ defined on each interval $I_i$. 
\\
\\
The first step of the Parareal algorithm is to solve $f(y(t),t)=0$ sequentially on the entire interval using the coarse scheme. This gives us a solution $Y(t)$ defined on the entire interval, and we can then use $\{\lambda_i^0=Y(T_i)\}_{i=1}^{N-1}$ as initial conditions for the decomposed equations $f_{i+1}(y_{i+1}^0(t),t)=0$. The second step is then to solve these equations in parallel using the fine scheme, which will result in one solution $y_i(t)$ on each interval $I_i$. The idea then, is to utilize the difference $S_i^0=y_i^0(T_{i})-\lambda_i^0$ between coarse and fine solution to repeat this process in an iteration. This is done by propagating the differences $S_i^0$ with the coarse solver, to update the initial conditions for each decomposed equation. These new initial conditions $\lambda_i^1$ can then be used to solve the decomposed equations $f_{i+1}(y_{i+1}^1(t),t)=0$ in parallel with the fine solver. We can then define updated differences $S_i^1=y_i^1(T_{i})-\lambda_i^1$ and repeat the iteration until we are satisfied with the solution. The version of Parareal presented in \cite{lions2001resolution} is only defined for linear equations. An alternative version of Parareal is found in \cite{baffico2002parallel}. The formulation given here is equivalent to the one in \cite{lions2001resolution} for linear equations, but is easier applied to non-linear equations.
\\
\\
A lot of the work done on the Parareal algorithm, has been focused on establishing its stability and convergence properties. The stability results are found in \cite{staff2005stability} and \cite{bal2005convergence}, where Staff in \cite{staff2005stability} derives sufficient conditions for the stability of Parareal for autonomous differential equations:
\begin{align}
\frac{\partial y}{\partial t} =\rho y,\quad y(0)=y_0,\quad  \rho<0 \label{autonom E}
\end{align}
while \cite{bal2005convergence} presents more general stability results for parabolic equations. The stability of Parareal applied is a more difficult for hyperbolic equations \cite{dai2013stable}. The convergence of Parareal is studied in \cite{lions2001resolution},\cite{bal2005convergence},\cite{gander2007analysis} and \cite{gander2007superlinear}.
\\
\\
Different applications of the algorithm exists for example on the Navier-Stokes problem\cite{fischer2005parareal}, for molecular-dynamics simulations\cite{baffico2002parallel}, on stochastic ordinary differential equations\cite{bal2003parallelization}, reservoir simulations \cite{garrido2005convergent}, fluid-structure\cite{farhat2003time}, or on the American put\cite{bal2002parareal}.
\\
\\
Since the Parareal algorithm is an iterative procedure, a stopping criteria for when to terminate the iteration is required. This is done in \cite{lepsa2010efficient}, where an error control mechanism for the Parareal algorithm to limit the number of Parareal iterations is introduced. The stopping criteria that they propose, is to stop the algorithm when the difference between coarse and fine solution at the subinterval boundaries $T_i$ are similar to the expected global error of the fine solver.\cite{aubanel2011scheduling}. One issue with Parareal, is that increasing the number of decompositions of the time domain, which we need to do if we want to increase the number of processes, will make the coarse discretization finer. This represents a possible bottleneck for speedup, which is adressed in \cite{rao2014adjoint}, where the authors try to parallelize PDEs in time in a scalable way, by only doing an initial coarse sequential solve, and thereafter doing everything in parallel. As mentioned in \cite{gander2007superlinear} the Parareal algorithm is not the first attempt to parallelize the solution of time dependent differential equation in temporal direction, since Nievergelt already in 1964 proposed a procedure in \cite{nievergelt1964parallel} that eventually led to the so called multiple shooting methods. A historic overview of the development of parallel in time algorithms can be found in \cite{gander201550}.
\\
\\
The Parareal algorithm parallelizes the solution process of time dependent differential equations. In \cite{maday2002parareal} extends Parareal, so that it can be used on optimal control problems with time dependent differential equation constraints. The problem looked at in \cite{maday2002parareal}, is: 
\begin{align*}
&\min_{y,u}J(y,u) = \frac{1}{2}\int_0^T||u(t)||_U^2dt + \frac{\alpha}{2}||y(T)-y^T||^2,\\
&\left\{
     \begin{array}{lr}
       	\frac{\partial y}{\partial t}+Ay = Bu\\
       	   y(0)=y_0
     \end{array}
   \right.
\end{align*}
We introduce parallelism in the same ways as we did for the differential equation case, by decomposing the time domain and equation. The continuity of the state equation between subintervals is enforced by adding a penalty term to the objective function $J$, that penalizes jumps in the solution of the state equation. This is based on the penalty method for constrained optimization described in \cite{nocedal2006numerical}. In \cite{maday2002parareal} they use quadratic penalty terms, which leads to the following modified objective function:
\begin{align}
J_{\mu}(y,u,\lambda_1,..,\lambda_{N-1})=J(y,u) +\frac{\mu }{2}\sum_{i=1}^{N-1}(y_i(T_i)-\lambda_i)^2 \label{lit_pen}
\end{align} 
Here $\lambda_i$ is the initial condition of the decomposed state equation $f(y_{i+1}(t),t)=0$. Solving both the original and moified optimal control problems require us to repeatedly evaluate the objective function and its gradient. Every time we do this we need to solve either the state equation, or the state equation and its adjoint. Decomposing the time interval allows us to solve these equations in parallel, and if we solve the modified problem with a sufficiently large penalty, we will end up with the solution of the original problem. One does not necessarily need a coarse level to make this parallel framework to produce a speedup. This is illustrated in \cite{rao2016time}, where the authors create a time-parallel algorithm for 4d variational data assimilation. The penalization of the objective function was done using the augmented Lagrangian approach, which is a variation of the penalization done in (\ref{lit_pen}). The experiments conducted in \cite{rao2016time} yielded limited success, since some speedup was achieved. However, the speedup was only attainable when using a parallel/sequential hybrid method, that first solved the penalized problem in parallel, for small penalty terms, and then used the parallel solution as an initial guess for the sequential algorithm. 
\\
\\
In \cite{maday2002parareal} the Parareal algorithm is reformulated as a preconditioner for the algebraic system that arises when we set $\lambda_i=y_{i}(T_i)$. Using this formulation the authors derive a preconditioner for the optimization algorithm that solves the penalized optimal control problem. The preconditioner they propose involves both a backward and a forward solve of the linearised state equation with a coarse solver, and it is to be applied to the $\lambda$ part of the gradient of $J_{\mu}$. The hope is that this Parareal based preconditioner will decrease the number of function and gradient evaluations needed for the optimization algorithm to converge, and the results in \cite{maday2002parareal} do indeed look promising. In an experiment with 100 cores, the authors report a theoretical speedup of around 400, which is superlinear. They do however believe that this result is due to properties of the example they choose, and do not expect superlinerar speedup as a general rule. The preconditioner for the optimal control problem can also be used as a modified Parareal algorithm, that is stable for hyperbolic equations \cite{chen2015adjoint}.
\\
\\
As mentioned the Parareal preconditioner presented in \cite{maday2002parareal} only affects the penalty terms. A more advanced preconditioner is derived in \cite{ulbrich2015preconditioners}, where the Parareal preconditioner is incorporated into a preconditioner for a control problem with time-dependent partial differential equation constraints and inequality constraints.
