\chapter{Summary and Conclusions} \label{summary chap}
The topic of this thesis is the parallelization of optimization problems with time-dependent differential equation constraints in temporal direction. The method we have proposed is developed around reducible problems, where the state equation constraint is well posed. Our method has been explained through a simple ODE constrained example problem, and we have also used this example for verification and testing. Even though we only considered an ODE example, we believe that our method also is applicable to time-dependent PDE constrained problems. We are then specifically thinking of problems where the constraints are on the following form:
\begin{align}
\left\{
     \begin{array}{lr}
       	u_t(x,t) + Au(x,t)=f \quad \textrm{for } \ (x,t)\in U\times(0,T),\\
       	u(x,0)=u_0(x).
     \end{array}
   \right. \label{PDE_exs}
\end{align}
Here $A$ is a differential operator. The reason for making this claim, is that after the spatial discretization is taken care of, evolving equations of type (\ref{PDE_exs}) through time is done in the same way as solving an ODE. 
\\
\\
The main contribution of this thesis is the analysis of the Parareal-based preconditioner $Q$ (\ref{Q_PC}) proposed in \cite{maday2002parareal} and the introduction of algorithm \ref{PPC_PEN_ALG}, based on the quadratic penalty method from section \ref{penalty_sec} and a preconditioned BFGS algorithm. The analysis of the Parareal-based preconditioner showed that $Q$ is positive definite and an approximation of the inverse Hessian of the penalized objective function. This made us able to use the preconditioner from \cite{maday2002parareal} in the BFGS algorithm as an initial inverse Hessian approximation. The Parareal-preconditioned BFGS algorithm is the central part of algorithm \ref{PPC_PEN_ALG}, proposed in section \ref{Algorithm_sec} as a parallel in time method for optimal control with DE constraints. The idea of this algorithm is to minimize the penalized objective function $\hat J_{\mu}$ for increasing penalty parameters $\mu$, using the preconditioned BFGS algorithm. When $\mu$ is sufficiently large, the minimizer of $\hat J_{\mu}$ will approximate the minimizer of $\hat J$.
\\
\\
An important aspect of our method is the evaluation of the reduced and penalized objective function $\hat J_{\mu}(v,\Lambda)$ and its gradient. In chapter \ref{disc_chap} we explained how to discretize $\hat J_{\mu}$ in context of the example problem, and we also explained how we can parallelize the evaluation of $\hat J_{\mu}$ and $\hat J_{\mu}'$. In chapter \ref{Verification chapter} we verified different features of our implementations of both the sequential and parallel algorithms for the example problem. In particular, we looked at the consistency of our method. We observed that the solution obtained by algorithm \ref{PPC_PEN_ALG} approached the numerical solution of the sequential algorithm when we increased the penalty parameter $\mu$. However, we also noticed, that when the difference between the function values of the sequential and parallel algorithm became close to machine precision, the control solution of the parallel algorithm stopped converging towards the sequential solution. This observation underlines a limitation of our algorithm. This limitation is that we can not always guarantee the consistency of our method, especially when the time steps used to dicretize the state equation become small.
\\
\\
In chapter \ref{Experiments chapter} we tested the performance of algorithm \ref{PPC_PEN_ALG} on an example problem. We measured the performance in both accuracy and potential speedup. What we were particularity interested in was investigating whether the performance of the preconditioned algorithm is independent of the parameters $N$, $n$ and $\mu$, representing number of decompositions, number of fine time steps and penalty parameter. What we found was that increasing the first two of these parameters did not significantly worsen the performance of algorithm \ref{PPC_PEN_ALG}. In the case of number of processes and decomposed intervals $N$, we even observed improved results when $N$ was increased. The most likely cause of this, is that when we increase $N$, the Parareal-based preconditioner $Q$ becomes an improved approximation of the inverse Hessian of $\hat J_{\mu}$. For the penalty parameter $\mu$, the picture became more nuanced. We observed that the computational cost remained roughly the same for increased $\mu$, until we reached the same order of error as the sequential solution. After this point increasing $\mu$ also increased the computational cost of minimizing $\hat J_{\mu}$. In chapter \ref{Experiments chapter} we also measured actual wall clock speedup for as many as 120 cores. This experiment was conducted on the Abel computer cluster, and we were able to achieve actual speedup. We for example obtained a speedup of 23.5 when using 120 cores. 
\section{Future Work}
The algorithm proposed in this thesis experiences trouble, when the penalty parameter gets large. Several strategies for improving the method and the Parareal preconditioner could be taken. One example is to replace the quadratic penalty method for removing the virtual constraints with the more advanced augmented Lagrangian method used in \cite{rao2016time}. Another potential improvement can perhaps be to find a preconditioner $Q_v$ that approximates the inverted Hessian of $\hat J(v)$, and then alter the Parareal-based preconditioner in the following way:
\begin{align*}
Q = \left[ \begin{array}{cc}
	Q_v & 0 \\
	0 & Q_{\Lambda} \\
	\end{array} \right]
\end{align*}
Different approaches to parallelization of optimal control in temporal direction might also be considered. One could for example try to restrict the parallelization to the differential equations. By this we mean solving the optimal control problem in the traditional way, but when we need to solve the state and adjoint equation, we solve these using for example the Parareal algorithm. Using this strategy to parallelize optimal control problems, would simplify the optimization, but also make solving the state and adjoint equations more complicated. Load bearing, which is simple for the method we have proposed would also become a more complicated issue if this alternative direction is chosen.
\\
\\
In this thesis we have tested algorithm \ref{PPC_PEN_ALG} for only one problem. It would be interesting to investigate how our proposed algorithm performs for other more complex problems. Since the problem we used was so easily solved, it was difficult to compute with the execution time of serial algorithm. If a more complex problem were solved, the potential might therefore be higher. Another issue that we have considered, is how to choose the coarse propagator $\bold G_{\Delta T}$, that the preconditioner is based on. This becomes more important when we are solving PDE constrained problems, since we then also have a spatial discretization. One could then consider a Parareal-based prpeconditioner defined by a propagator $\bold G_{\Delta T}$  that uses a coarse dicretization in both space and time.



