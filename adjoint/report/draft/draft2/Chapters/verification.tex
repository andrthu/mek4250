\chapter{Verification}\label{Verification chapter}
In this chapter we will verify implementations of the algorithm presented in chapter \ref{method_chap} using the discritization detailed in chapter \ref{disc_chap}. All implementations are done in the python programming language, and the numerics is done using the NumPy\cite{walt2011numpy} library. Plots are created using the matplotlib\cite{Hunter:2007} package, tables are auto generated using Pandas\cite{mckinney2010data} and the parallel parts are implemented using the mpi4py\cite{dalcin2007mpi4py} library. We test our algorithm using the example problem (\ref{exs_J}-\ref{exs_E}), with the following parameters:
\begin{align}
&J(y,v) = \frac{1}{2}\int_0^1v(t)^2dt + \frac{1}{2}(y(1)-11.5)^2 \label{test_J}\\
&\left\{
     \begin{array}{lr}
       	y'(t) = -3.9y(t)+v(t) \ t\in(0,1)\\
       	y(0)=3.2
     \end{array}
   \right. \label{test_E}
\end{align}
Using this problem we will first test the numerical gradients stated in section \ref{num_grad_sec1} and \ref{num_grad_sec2}, and then investigate if the minimizer of the discretized objective function converges to the exact minimizer derived in section \ref{exact_sec}. We also check if the theoretical speedup for objective function and gradient evaluation suggested in \ref{analysis sec} is in line with actual measurements. The last test done is on the consistency of the penalty framework. 
\section{Taylor test} \label{Taylor_sec}
The Taylor test is a good way to test the correctness of the gradient of a function. The test is as its name implies connected with Taylor expansions of a function, or more precisely the following two observations:
\begin{align*}
|J(v+\epsilon w)-J(v)| &= \mathcal{O}(\epsilon) \\
|J(v+\epsilon w)-J(v)-\epsilon\nabla J(v)\cdot w| &= \mathcal{O}(\epsilon^2)
\end{align*}
Here $w$ is a vector in the same space as $v$, while $\epsilon>0$ is a constant. The test is carried out by evaluating $D=|J(v+\epsilon w)-J(v)-\epsilon\nabla J(v)\cdot w|$ for decreasing $\epsilon$'s, and if $D$ approaches 0 at 2nd order rate, we consider the test as passed.
\subsection{Verifying the numerical gradient using the Taylor test}
We will now use the Taylor test on the discrete gradient stemming from problem (\ref{test_J}-\ref{test_E}). We discretize this problem using the Crank-Nicolson scheme for the state and adjoint equation, and the trapezoid rule for numerical integration, as suggested in chapter \ref{disc_chap}. We let the time step be $\Delta t=\frac{1}{100}$, and evaluate the objective function and its gradient using the control variable $v=1$. To apply the Taylor test, we need a direction $w\in\mathbb{R}^{101}$, which we set to be a vector with components randomly chosen from numbers between 0 and 100. To make table \ref{Taylor_tab1} more readable we define the following measures:
\begin{align}
D_1(\epsilon) &= |J(v+\epsilon w)-J(v)| \label{D1} \\
D_2(\epsilon) &=|J(v+\epsilon w)-J(v)-\epsilon \nabla J(v)\cdot w|\label{D2}
\end{align} 
We evaluate $D_1(\epsilon)$ and $D_2(\epsilon)$ for decreasing $\epsilon$s, and list the results in table \ref{Taylor_tab1}.
\\
\begin{table}[h]
\caption{Taylor test for non-penalized discrete objective function}
\label{Taylor_tab1}
\centering
\begin{tabular}{lrrrll}
\toprule
{} $\epsilon$&  $D_1$ &  $D_2$ &        $||\epsilon w||_{l_{\infty}}$ &    $ \log(\frac{D_1(10\epsilon)}{D_1(\epsilon)})$ &    $ \log(\frac{D_2(10\epsilon)}{D_2(\epsilon)})$ \\
\midrule
1.000000e+00 &  5956.494584 &        5.244487e+03 &  99.987417 &       -- &       -- \\
1.000000e-01 &   123.645671 &        5.244487e+01 &   9.998742 &  1.68281 &        2 \\
1.000000e-02 &     7.644529 &        5.244487e-01 &   0.999874 &  1.20883 &        2 \\
1.000000e-03 &     0.717253 &        5.244487e-03 &   0.099987 &  1.02768 &        2 \\
1.000000e-04 &     0.071253 &        5.244487e-05 &   0.009999 &  1.00287 &        2 \\
1.000000e-05 &     0.007121 &        5.244489e-07 &   0.001000 &  1.00029 &        2 \\
1.000000e-06 &     0.000712 &        5.244760e-09 &   0.000100 &  1.00003 &  1.99998 \\
1.000000e-07 &     0.000071 &        5.255194e-11 &   0.000010 &        1 &  1.99914 \\
\bottomrule
\end{tabular}
\end{table}
\\
\\
Table \ref{Taylor_tab1} clearly shows that $|J(v+\epsilon w)-J(v)-\epsilon \nabla J(v)\cdot w|$ converges to zero at a second order rate. This means that the numerical gradient of our test problem passes the Taylor test. This again indicates that both the numerical gradient and the implementation of it are correct. Let us then check if this is also the case for the penalized problem.
\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{num_grad.png}
\caption{Gradient of non-penalized objective function, with focus on the two ends. Also included is a plot with a finite difference approximation to the gradient.}
\end{figure}
\subsection{Verifying the penalized numerical gradient using the Taylor test}
We will now use the Taylor test on the penalized numerical gradient (\ref{num_pen_grad_lam}-\ref{num_pen_grad_v}) that we get when decomposing $I=[0,T]$ into $N=10$ subintervals while solving the same problem as in the test for the gradient of the non-penalized objective function (\ref{test_J}-\ref{test_E}). We then discretize in time using $\Delta t=\frac{1}{100}$. The control variable is now a vector $v\in\mathbb{R}^{N+m}$ and we set $v_k=0 \ \forall k=0,...,N+n-1$, while the $w_k$s are chosen randomly from numbers between 0 and 100. The results of applying the Taylor test to this problem are given in table \ref{Taylor_tab2}. Here $D_1$ and $D_2$ are again defined as in (\ref{D1}-\ref{D2}).
\\
\begin{table}[!h]
\caption{Taylor test for penalized discrete objective function}
\centering
\label{Taylor_tab2}
\begin{tabular}{lrrrll}
\toprule
{}$\epsilon$&  $D_1$ &  $D_2$ &        $||\epsilon w||_{l_{\infty}}$ &    $ \log(\frac{D_1(10\epsilon)}{D_1(\epsilon)})$ &    $ \log(\frac{D_2(10\epsilon)}{D_2(\epsilon)})$  \\
\midrule
1.000000e+00 &  1.080513e+04 &        1.076907e+04 &  9.771288e+01 &       -- &       -- \\
1.000000e-01 &  1.112972e+02 &        1.076907e+02 &  9.771288e+00 &  1.98715 &        2 \\
1.000000e-02 &  1.437558e+00 &        1.076907e+00 &  9.771288e-01 &  1.88886 &        2 \\
1.000000e-03 &  4.683423e-02 &        1.076907e-02 &  9.771288e-02 &  1.48706 &        2 \\
1.000000e-04 &  3.714207e-03 &        1.076907e-04 &  9.771288e-03 &   1.1007 &        2 \\
1.000000e-05 &  3.617285e-04 &        1.076907e-06 &  9.771288e-04 &  1.01148 &        2 \\
1.000000e-06 &  3.607593e-05 &        1.076908e-08 &  9.771288e-05 &  1.00117 &        2 \\
1.000000e-07 &  3.606624e-06 &        1.076979e-10 &  9.771288e-06 &  1.00012 &  1.99997 \\
1.000000e-08 &  3.606527e-07 &        1.086074e-12 &  9.771288e-07 &  1.00001 &  1.99635 \\
\bottomrule
\end{tabular}
\end{table}
\\
\\
Again we see that $|J(v+\epsilon w)-J(v)-\epsilon \nabla J(v)\cdot w|$ converges to zero at a second order rate, meaning that the penalized numerical gradient also passes the Taylor test.
\begin{figure}[!h]
\centering
\includegraphics[scale=0.5]{pen_num_grad.png}
\caption{Plots showing the $\Lambda$ and control part of the numerical gradient found using formula (\ref{num_pen_grad_lam}-\ref{num_pen_grad_v}) and finite difference}
\end{figure}
\section{Convergence rate of solver for the non-penalized problem}
In section \ref{Taylor_sec} we demonstrated that our implementation of the gradients for different discretizations of the objective function introduced in theorem \ref{Theorem_num_grad} and \ref{Theorem_penalty_grad} satisfy the Taylor test. Since the discretized objective function $\hat J_{\Delta t}$ and its gradient pass the Taylor test, we expect that we can find the minimizer $\bar v$ of $\hat J_{\Delta t}$ by using an optimization algorithm. What we now want to find out, is if the minimizer of the discrete objective function converges towards the exact minimizer derived in section \ref{exact_sec}. We investigate this by solving optimal control problem (\ref{test_J}-\ref{test_E}) using both a Crank-Nicolson and an implicit Euler discretization. To measure the difference between exact optimal control $v_e$ and the numerical optimal control $v$ we look at the relative maximal difference between $v_e$ and $v$ for $t\in(0,T)$, meaning
\begin{align}
||v|| = \max_{k=1,...,n-1}|v_k| \label{inner_norm}
\end{align} 
We also look at the relative difference in objective function value between the controls. For both these measures, we calculate at what rate they converge to zero for decreasing $\Delta t$ values. The results for the implicit Euler discirization is found in table \ref{IE_convergence}, while Crank-Nicolson results are given in table \ref{CN_convergence}.
\begin{table}[!h]
\caption{Convergence of implicit Euler numerical sequential solver of optimal control problem.}\label{IE_convergence}
\centering
\begin{tabular}{lrrll}
\toprule
{} $\Delta t$&    $\frac{||v_e-v||}{||v||}$ &  $\frac{\hat J(v_e)-\hat J(v)}{\hat J(v_e)}$ &   norm rate &    functional rate \\
\midrule
0.02000 &  0.212619 &  1.709101e-02 &        -- &       -- \\
0.01000 &  0.136096 &  4.506561e-03 & -0.643642 & -1.92314 \\
0.00100 &  0.017469 &  4.703915e-05 & -0.891585 & -1.98139 \\
0.00010 &  0.001795 &  4.722900e-07 &   -0.9883 & -1.99825 \\
0.00001 &  0.000180 &  4.724790e-09 &  -0.99882 & -1.99983 \\
\bottomrule
\end{tabular}
\end{table}
Notice that the convergence rate of the norm difference in table \ref{IE_convergence} approaches one when $\Delta t$ tends to zero. This is consistent with what we would expect for a finite difference scheme of first order. We also notice that the difference in function value converges an order of one faster towards zero than the control difference.  
\begin{table}[!h]
\caption{Convergence of Crank-Nicolson numerical sequential solver of optimal control problem.}\label{CN_convergence}
\centering
\begin{tabular}{lrrll}
\toprule
{} $\Delta t$&    $\frac{||v_e-v||}{||v||}$ &  $\frac{\hat J(v_e)-\hat J(v)}{\hat J(v_e)}$ &   norm r &    val r \\
\midrule
0.02000 &  4.177702e-02 &  2.309886e-03 &       -- &       -- \\
0.01000 &  1.109500e-02 &  3.383020e-04 &  -1.9128 & -2.77144 \\
0.00100 &  1.189515e-04 &  3.931451e-07 & -1.96976 & -2.93475 \\
0.00010 &  1.421834e-06 &  3.992950e-10 & -1.92252 & -2.99326 \\
0.00001 &  1.480190e-08 &  3.978299e-13 & -1.98253 &  -3.0016 \\
\bottomrule
\end{tabular}
\end{table}
The results of table \ref{CN_convergence} show results similar to the ones in table \ref{IE_convergence}, however the convergence rates using a Crank-Nicolson scheme to discretize the ODEs are one order higher than the rates we got using implicit Euler. This is again expected since the Crank-Nicolson scheme is of order two. In both tables we observe that $\frac{\hat J(v_e)-\hat J(v)}{\hat J(v)}$ is always positive, which means that $\hat J(v_e)>\hat J(v)$. This makes sense, since $\hat J$ here means the discrete objective function, and $v$ is the minimum of this function, while $v_e$ is the minimum of the continuous objective function. One last remark concerns the choice of norm (\ref{inner_norm}). This norm excludes the values of $v$ and $v_e$ at $t=0$ and $t=T$. If these points are included, we do not see the convergence rates given in table \ref{IE_convergence} and \ref{CN_convergence}. 
\section{Verifying function and gradient evaluation speedups} \label{ver S sec}
In \ref{analysis sec} we derived the theoretical speedup for numerical gradient and objective function evaluation when decomposing the time-interval. It would now be interesting to check if the implementation achieves the theoretical speedup for our example problem (\ref{test_J}-\ref{test_E}). Now let us explain the experimental setting. A computer with 6 cores was used to verify the results of section \ref{analysis sec}. Having 6 cores means that we can do gradient and function evaluation for $N=1,2,...,6$ decompositions with different time step sizes $\Delta t$. For each combination of $N$ and $\Delta t$, we will run the function and gradient evaluations ten times, and then choose the the smallest execution time produced by the ten runs. The speedup is then calculated by dividing the sequential execution time by the parallel execution time. Tables \ref{Speed_table1}-\ref{speed_table_end} below shows runtime and speedup for both gradient and function evaluation for different $\Delta t$s and $N$s. All evaluations are done with control input $v=1$ and $\lambda_i=1$.  
\\
\begin{table}[!h]
\centering
\caption{$\Delta t=10^{-2}$}
\label{Speed_table1}
\begin{tabular}{lrrrr}
\toprule
{}$N$ &  functional time(s) &  gradient time(s) &  functional speedup &  gradient speedup \\
\midrule
1 &           0.000196 &          0.000217 &            1.000000 &          1.000000 \\
2 &           0.000207 &          0.000248 &            0.946860 &          0.875000 \\
3 &           0.000251 &          0.000288 &            0.780876 &          0.753472 \\
4 &           0.000305 &          0.000343 &            0.642623 &          0.632653 \\
5 &           0.000360 &          0.000396 &            0.544444 &          0.547980 \\
6 &           0.000458 &          0.000452 &            0.427948 &          0.480088 \\
\bottomrule
\end{tabular}
\end{table}
\begin{table}[!h]
\centering
\caption{$\Delta t=10^{-4}$}
\begin{tabular}{lrrrr}
\toprule
{} $N$&  functional time(s) &  gradient time(s) &  functional speedup &  gradient speedup \\
\midrule
1 &           0.008877 &          0.015016 &            1.000000 &          1.000000 \\
2 &           0.004475 &          0.007713 &            1.983687 &          1.946843 \\
3 &           0.003127 &          0.005332 &            2.838823 &          2.816204 \\
4 &           0.002478 &          0.004083 &            3.582324 &          3.677688 \\
5 &           0.002080 &          0.003369 &            4.267788 &          4.457109 \\
6 &           0.001964 &          0.003016 &            4.519857 &          4.978780 \\
\bottomrule
\end{tabular}
\end{table}
\begin{table}[!h]
\centering
\caption{$\Delta t=10^{-5}$}
\begin{tabular}{lrrrr}
\toprule
{} $N$&  functional time(s) &  gradient time(s) &  functional speedup &  gradient speedup \\
\midrule
1 &           0.087484 &          0.154841 &            1.000000 &          1.000000 \\
2 &           0.043598 &          0.075660 &            2.006606 &          2.046537 \\
3 &           0.030286 &          0.052114 &            2.888595 &          2.971198 \\
4 &           0.022356 &          0.038681 &            3.913222 &          4.003025 \\
5 &           0.018045 &          0.031463 &            4.848102 &          4.921368 \\
6 &           0.016126 &          0.026905 &            5.425028 &          5.755101 \\
\bottomrule
\end{tabular}
\end{table}
\begin{table}[!h]
\centering
\caption{$\Delta t=10^{-7}$}
\label{speed_table_end}
\begin{tabular}{lrrrr}
\toprule
{}$N$ &  functinal time(s) &  gradient time(s) &  functional speedup &  gradient speedup \\
\midrule
1 &           8.350907 &         14.930247 &            1.000000 &          1.000000 \\
2 &           4.200743 &          7.233497 &            1.987960 &          2.064043 \\
3 &           2.932549 &          5.033368 &            2.847662 &          2.966254 \\
4 &           2.190376 &          3.861509 &            3.812545 &          3.866428 \\
5 &           1.796729 &          3.089178 &            4.647839 &          4.833081 \\
6 &           1.524042 &          2.599027 &            5.479447 &          5.744552 \\
\bottomrule
\end{tabular}
\end{table}
\\
\\
Since the parallel algorithm has some overhead, we do not expect any improvements for small problems. This is reflected in the above results, where we for $\Delta t = 10^{-2}$ see an increased execution time when running function and gradient evaluation in parallel. For $\Delta t = 10^{-4}$ we see only a modest speedup, that is significantly lower than the expected speedup from section \ref{analysis sec}. For $\Delta t \leq 10^{-5}$, however we see speedup results in line with what we expect from the theory.  
\section{Consistency}
When we introduced the penalty method in section \ref{penalty_sec}, we also presented a result showing that the iterates $\{v^k\}$ stemming from the penalty algorithmic framework converged towards the solution of the non-penalized problem $v$. We can write this up as:
\begin{align*}
\lim_{k\rightarrow\infty} v^k = v 
\end{align*}  
An alternative way of looking at this, is to let $v^{\mu}$ be the minimizer of $\hat J_{\mu}$, and instead write the above limit as:
\begin{align}
\lim_{\mu\rightarrow\infty} v^{\mu} = v \label{mu con}
\end{align}
The interpretation of the above limit, is that solving the penalized problem with an ever increasing penalty parameter $\mu$ should result in a solution that is getting closer and closer to the solution of the non-penalized problem. This means that the penalty algorithm is consistent, since it produces the same solution as the ordinary non-decomposed problem. It is therefore worth checking if the implementation of the penalized problem actually has the property (\ref{mu con}). We investigate this by comparing the solution we get by decomposing and then applying the penalty method on problem (\ref{test_J}-\ref{test_E}) with the solution we get by solving the undecomposed problem. 
\\
\\
We discretize (\ref{test_J}-\ref{test_E}) using Crank-Nicolson and the trapezoid rule for two different time steps. First we let $\Delta t = 10^{-2}$ and apply the penalty method for $N=2$ and $N=10$ decompositions, we then let $\Delta t = 10^{-3}$ and test the penalty method on $N=2$ and $N=7$ decompositions. We use different metrics to compare the non-penalized and penalized solutions, so that we better see how the solution of the penalized problem behaves when we solve it for an increasing sequence of $\mu$ values. We define the metrics as follows:
\begin{align*}
\textrm{Realtive objective function differnce:}\quad A &= \frac{\hat{J}(v_{\mu})-\hat{J}(v)}{\hat{J}(v)}\\
\textrm{Realtive penalized objective function differnce:}\quad B &= \frac{\hat{J}_{\mu}(v)-\hat{J}_{\mu}(v_{\mu})}{\hat{J}_{\mu}(v)}\\
\textrm{Relative control $L^2$-norm difference:}\quad C&=\frac{||v_{\mu}-v||_ {L^2}}{||v||_{L^2}} \\
\textrm{Maximal jump in decomposed state equation:}\quad D&= \sup_i\{y_{k_i}^i-y_{k_i}^{i+1}\}\\
\end{align*}
Notice that both $A$ and $B$ should be grater than $0$, since $v$ and $v_{\mu}$ are the minimizers of $\hat J$ and $\hat J_ {\mu}$. The measure of jumps in the state equation $D$ is added to check that the penalty solution approaches a feasible solution in context of the continuity constraints (\ref{Extra constraints}). The results of the above detailed experiment are presented through logarithmic plots in figure \ref{Cons1_fig} and \ref{Cons2_fig}. 
\\
\\
\begin{figure}[!h]
\centering
\includegraphics[scale=0.5]{consistency1.png}
\caption{Logarithmic plot showing how solution of penalty method applied to problem (\ref{test_J}-\ref{test_E}) develops for $\Delta t = 10^{-2}$.}
\label{Cons1_fig}
\end{figure}
\begin{figure}[!h]
\centering
\includegraphics[scale=0.5]{consistency2.png}
\caption{Same as figure \ref{Cons1_fig}, only now $\Delta t = 10^{-3}$.}
\label{Cons2_fig}
\end{figure}
The plots in figure \ref{Cons1_fig} and \ref{Cons2_fig} all show a similar picture, and we observe that all measures decrease when the penalty parameter is increased. Still there are several parts of the plots worthy of note. The measure $A$ related to the unpenalised objective function is the value that converges to zero the fastest. If we look at the vales of $A$ before the machine precision is reached we see that $A$ is proportional to $\frac{C}{\mu^2}$. The convergence rate of $A$ for $\Delta t=10^{-2}$ and $N=2$ is shown in table \ref{Cosn_rate_table} together with the rate convergence rate of $C$. $C$ and the other measures converge to zero at a rate of one, however we see that the relative error between the controls $v$ and $v_{\mu}$ $C$ stops to decrease long before the machine precision is reached. It seems that this barrier is hit around the same time as $A$ approaches machine precision. The reason for this probably is that small changes in the control $v_{\mu}$ no longer registers in $\hat J_{\mu}$, and it is therefore difficult to find an appropriate step length in the line search method.
\\
\\
$B$ and $D$ on the other hand continue to decrease steadily towards zero, even after $A$ has hit machine precision. The $B$ and $C$ metrics are both related to the $\frac{\mu }{2}\sum_{i=1}^{N-1}(y^i(T_{i})-\lambda_i)^2$ term, which is the part that enforces the continuity constraints (\ref{Extra constraints}). This means that after a certain point, the penalty method only improves the $\Lambda$ part of the control, while $v$ remains the same. 
\begin{table}[!h]
\centering
\caption{Convergence rates for $\Delta t=10^{-2}$ and $N=2$. Notice how the $||v_{\mu}-v||$ stops to decrease at around the same time as $\frac{J(v_{\mu})-J(v)}{J(v)}$ hits machine precision.}
\label{Cosn_rate_table}
\begin{tabular}{lrrll}
\toprule
{} $\mu$&  $\frac{J(v_{\mu})-J(v)}{J(v)}$ &   $||v_{\mu}-v||$ &        A rate &        C rate \\
\midrule
1.000000e+01 &      4.105697e-07 & 1.790231e-03 &            -- &            -- \\
1.000000e+02 &      4.119052e-09 & 1.793140e-04 & -1.998590 & -0.9992948 \\
1.000000e+03 &      4.120272e-11 & 1.793401e-05 & -1.999871 & -0.9999368 \\
1.000000e+04 &      4.137632e-13 & 1.796793e-06 & -1.998174 & -0.9991795 \\
2.000000e+04 &      1.058008e-13 & 9.076756e-07 & -1.967455 & -0.9851756 \\
5.000000e+04 &      1.789909e-14 & 3.733858e-07 & -1.939131 & -0.9694245 \\
7.000000e+04 &      7.968773e-15 & 2.444327e-07 & -2.405011 & -1.259160 \\
1.000000e+05 &      4.045685e-15 & 1.730018e-07 & -1.900553 & -0.9690555 \\
2.000000e+05 &      4.045685e-15 & 1.721746e-07 &  0.000000 & -0.0069153 \\
3.000000e+05 &      3.923088e-15 & 1.719606e-07 & -0.007589 & -0.0030671 \\
4.000000e+05 &      3.800492e-15 & 1.718652e-07 & -0.110360 & -0.0019278 \\
5.000000e+05 &      3.677895e-16 & 4.545076e-08 & -10.46580 & -5.960652e \\
\bottomrule
\end{tabular}

\end{table}
