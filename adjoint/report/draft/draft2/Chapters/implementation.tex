\chapter{Implementation}
In previous chapters we have derived the adjoint equation and the gradient for our example optimal control problem with ODE constraints. We have also explained how we can parallelize the solving of the state and adjoint equations using the penalty method, and we have introduced a prconditioner for our optimization algorithms based on the parareal scheme. Before we can start to test our parallel algorithm, we need to discretize the time domain, the equations, the objective function and its gradient. 
\\
\\
We discretize $I=[0,T]$ by dividing it into $n$ parts of length $\Delta t=\frac{T}{n}$, and settting $t_k=k\Delta t$. This gives us a sequence $I_{\Delta t}=\{t_k\}_{k=0}^{n}$ as a discrete representation of the interval $I$. Using $I_{\Delta t}$ we can start to discretize our example problem.
\section{Discretizing the non-penalized example problem}
Let us remember our example state equation (\ref{exs_E}) and objective function (\ref{exs_J}) 
\begin{align}
\left\{
     \begin{array}{lr}
       	y'(t)=\alpha y(t) +v(t), \ t \in (0,T)\\
       	   y(0)=y_0
     \end{array}
   \right. \label{equation}
\end{align}
\begin{align}
J(y,v) = \frac{1}{2}\int_0^Tv(t)^2dt + \frac{1}{2}(y(T)-y^T)^2
\label{problem}
\end{align}
We know that the the reduced gradient of (\ref{problem}) is:
\begin{align}
\nabla\hat{J}(v) = v(t)+p(t) \label{gradiant}
\end{align}
where $p$ is the solution of the adjoint equation:
\begin{align}   
  \left\{
     \begin{array}{lr}
	-p'(t) = \alpha p(t) \\
	p(T) = y(T)-y^T     \
	\end{array}
   \right. \label{adjoint}
\end{align}
We now want to discretize (\ref{equation}-\ref{adjoint}), so we can solve the problem numerically. What we particularly want, is an expression for the gradient. 
\subsection{Finite difference}
Before I state what the numerical gradient will be for the implicit end explicit Euler schemes, I will write up these schemes for our equations (\ref{equation}) and (\ref{adjoint}). First the implicit for the state equation:
\begin{align}
\frac{y^k-y^{k-1}}{\Delta t} &= \alpha y^{k} + v^{k} \\
(1-\alpha\Delta t)y^{k} &= y^{k-1} +\Delta t v^{k} \\
y^k &=\frac{y^{k-1} +\Delta t v^{k}}{1-\alpha\Delta t} \label{I_state}
\end{align}
Implicit Euler for the adjoint equation:
\begin{align}
-\frac{p^k-p^{k-1}}{\Delta t} -\alpha p^{k-1} &=0 \\
(1-\Delta t\alpha)p^{k-1}&=p^k \\
p^{k-1} &= \frac{p^k}{1-\Delta t\alpha} \label{I_adjoint}
\end{align}
The explicit scheme for the state equation reads:
\begin{align}
\frac{y^{k+1}-y^{k}}{\Delta t} &= \alpha y^{k} + v^{k} \\
y^{k+1}&=(1 +\Delta t\alpha) y^{k} + \Delta t v^{k}\label{E_state}
\end{align} 
and the for the adjoint we have:
\begin{align}
-\frac{p^k-p^{k-1}}{\Delta t} -\alpha p^{k} &=0 \\
p^{k-1} &=p^k(1 +\Delta t\alpha)\label{E_adjoint}
\end{align}
With these formulas in mind lets find the numerical gradient of our example problem.
\subsection{Numerical gradient}
\begin{theorem}
Discretizing the adjoint and state equation using the implicit Euler finite difference scheme, and evaluating the integral in the functional using the trapezoid rule, means that the numerical gradient will look like the following:
\begin{align}
\nabla J_{\Delta t}(v_{\Delta t}) = Mv_{\Delta t} + Bp_{\Delta t} \label{num_grad}
\end{align}
where $M$ and $B$ are the matrices:
\begin{align*}
M=\left[ \begin{array}{cccc}
   \frac{1}{2}\Delta t & 0 & \cdots & 0 \\  
   0& \Delta t & 0 & \cdots \\ 
   0 &0 & \Delta t  & \cdots \\
   0 &\cdots &0 & \frac{1}{2}\Delta t   \\
   \end{array}  \right] 
,B = \left[ \begin{array}{cccc}
   0& 0 & \cdots & 0 \\  
   \Delta t& 0 & 0 & \cdots \\ 
   0 & \Delta t& 0  & \cdots \\
   0 &\cdots & \Delta t& 0   \\
   \end{array}  \right] 
\end{align*}
If one instead uses the explicit Euler finite difference scheme on the differential equations, the gradient will instead look like:
\begin{align*}
\nabla J_{\Delta t}(v_{\Delta t}) = Mv_{\Delta t} + B^*p_{\Delta t}
\end{align*}
\end{theorem}
\begin{proof}
Let us start with the $Mv$ term of the gradient. This term comes from the integral $\int_0^T v(t)^2dt$, which we evaluate using the trapezoid rule, which looks as the following:
\begin{align*}
\int_0^T v(t)^2dt \approx \Delta t\frac{v_0^2+v_n^2}{2} + \sum_{i=1}^{n-1} \Delta t v_i^2 = v^*Mv
\end{align*} 
The function $f(v)=\frac{1}{2} v^*Mv$ obviously has $Mv$ as gradient. The second term of the gradient comes from the second term of the functional, namely $g(v)=\frac{1}{2}(y^n -y^T)^2$. To differentiate $g$ with respect to the i'th component of $v$, we will apply the chain rule multiple times. Lets first demonstrate by calculating $\frac{\partial g}{\partial v_n}$, in a setting where we have used implicit euler to solve the equations:
\begin{align*}
\frac{\partial g(v)}{\partial v_n} &= \frac{\partial g(v)}{\partial y_n}\frac{\partial y_n}{\partial v_n} = (y_n -y^T)\frac{\partial y_n}{\partial v_n}\\
&= (y_n -y^T)\frac{\Delta t}{1-\alpha\Delta t}
\end{align*}
To get to the second line I used the implicit Euler formula (\ref{I_state}). If we then look at the scheme (\ref{I_adjoint}) for the adjoint equation, we see that:
\begin{align*}
(y_n -y^T)\frac{\Delta t}{1-\alpha\Delta t} = \Delta t\frac{p_n}{1-\alpha\Delta t} = \Delta t p_{n-1}
\end{align*} 
Using the same approach, we can find an expression for $\frac{\partial g(v)}{\partial v_i}$: 
\begin{align*}
\frac{\partial g(v)}{\partial v_i} &= (y_n -y^T) (\prod_{k=i+1}^{n}\frac{\partial y_{k}}{\partial y_{k-1}}) \frac{\partial y_i}{\partial v_{i}} = \frac{p_n}{(1-\alpha\Delta t)^{n-i}}\frac{\Delta t}{1-\alpha\Delta t} \\
&= \frac{p_n\Delta t}{(1-\alpha\Delta t)^{n-i+1}}=\Delta t p_{i-1}
\end{align*}
since $v_0$ is not part of the scheme, $\frac{\partial g(v)}{\partial v_0}=0$. If we now write up the gradient of $g(v)$ on matrix form, you get $\nabla g(v) = Bp$. The expression for the gradient in the case where we use the explicit Euler scheme can be found in a similar fashion. 
\end{proof}
\subsection{Taylor test}
A good way to test whether a proposed gradient of functional actually is the correct gradient, is to use the Taylor test. The test is as its name implies connected with Taylor expansions of a function, or more precisely the following two observations:
\begin{align*}
|J(v+\epsilon w)-J(v)| &= O(\epsilon) \\
|J(v+\epsilon w)-J(v)-\epsilon\nabla J(v)\cdot w| &= O(\epsilon^2)
\end{align*}
Here $w$ is a random direction in the same space as $v$, while $\epsilon$ is some constant. 
\\
\\
The test is carried out, by evaluating $D=|J(v+\epsilon w)-J(v)-\epsilon\nabla J(v)\cdot w|$ for decreasing $\epsilon$s, and if $D$ approaches 0 at 2nd order rate, we consider the test as passed.
\subsection{Verifying the numerical gradient using the Taylor test}
I will now use the Taylor test on the numerical gradient (\ref{num_grad}) that we get when solving the following problem:
\begin{align}
\left\{
     \begin{array}{lr}
       	y'(t)=0.9y(t) +v(t), \ t \in (0,1)\\
       	   y(0)=3.2
     \end{array}
   \right. 
\end{align}
\begin{align}
J(y,v) = \frac{1}{2}\int_0^1v(t)^2dt + \frac{1}{2}(y(1)-1.5)^2
\end{align}
I then discretize in time using $\Delta t=\frac{1}{100}$, and I set $v_i=1 \ \forall i$, while $w_i$ are chosen randomly from numbers between 0 and 100. Applying the Taylor test to this problem, and setting:
\begin{align*}
D_1(\epsilon) &= |J(v+\epsilon w)-J(v)|\\
D_2(\epsilon) &=|J(v+\epsilon w)-J(v)-\epsilon \nabla J(v)\cdot w|
\end{align*} 
yielded the following:
\\
 \begin{tabular}{lrrrll}
\toprule
{} $\epsilon$&  $D_1$ &  $D_2$ &        $||\epsilon w||_{l_{\infty}}$ &    $ \log(\frac{D_1(10\epsilon)}{D_1(\epsilon)})$ &    $ \log(\frac{D_2(10\epsilon)}{D_2(\epsilon)})$ \\
\midrule
1.000000e+00 &  5956.494584 &        5.244487e+03 &  99.987417 &       -- &       -- \\
1.000000e-01 &   123.645671 &        5.244487e+01 &   9.998742 &  1.68281 &        2 \\
1.000000e-02 &     7.644529 &        5.244487e-01 &   0.999874 &  1.20883 &        2 \\
1.000000e-03 &     0.717253 &        5.244487e-03 &   0.099987 &  1.02768 &        2 \\
1.000000e-04 &     0.071253 &        5.244487e-05 &   0.009999 &  1.00287 &        2 \\
1.000000e-05 &     0.007121 &        5.244489e-07 &   0.001000 &  1.00029 &        2 \\
1.000000e-06 &     0.000712 &        5.244760e-09 &   0.000100 &  1.00003 &  1.99998 \\
1.000000e-07 &     0.000071 &        5.255194e-11 &   0.000010 &        1 &  1.99914 \\
\bottomrule
\end{tabular}
\section{Discretizing the decomposed time-domain}
Decomposing the time interval $I=[0,T]$ into $N$ equally sized subintervals $I_i=[T_i,T_{i+1}]$, and solving the state and adjoint equations separately on each subinterval, allows our algorithm to be run in parallel. Decomposing $I$ is simple in the continuous case, however in practice we are solving these equations numerically, and in the discrete case, partitioning $I$ is more involved. To explain how we decompose $I$ in the discrete case, lets look at how to do it for the state equation. Define a differential equation $F$:
\begin{align*}
\left\{
     \begin{array}{lr}
		F(y(t),v(t))=0 \	\textit{For $t \in [0,T]$} \\
		y(0)=y_0
	\end{array}
   \right.	
\end{align*} 
We then decompose $I$, and assume that we have $N-1$ intermediate initial conditions $\{\lambda_i\}_{i=1}^{N-1}$, such that we get a solvable equation on each subinterval:
\begin{align*}
\left\{
     \begin{array}{lr}
		F^i(y_i(t),v(t))=0 \	\textit{For $t \in [T_i,T_{i+1}]$} \\
		y(T_i)=\lambda_i
	\end{array}
   \right.	
\end{align*} 
Now lets look at what happens when we discretize $I$. Lets divide $I$ into $n$ parts of length $\Delta t=\frac{T}{n}$, and set $t_k=k\Delta t$. This gives us a sequence $I_{\Delta t}=\{t_k\}_{k=0}^{n}$ as a discrete representation of the interval $I$. Using some finite difference scheme, we can transform the differential equation $F$ into a difference equation $F_{\Delta t}$:
    \begin{align*}
\left\{
     \begin{array}{lr}
		F_{\Delta t}(y^k,v(t_k))=0 \	\textit{For $k=1,...,n$} \\
		y^0=y_0
	\end{array}
   \right.	
\end{align*} 
The next step is to decompose the discrete interval $I_{\Delta t}$ into $N$ discrete subintervals. This is simply done by extracting a subsequence $\{t_{k_i}\}_{i=0}^N\subset I_{\Delta t}$ where $t_{k_0}=t_0$ and $t_{k_N}=t_n$. This results in $N$ sequences on the form $I_{\Delta t}^i=\{t_{k_i},t_{k_i+1},...,t_{k_{i+1}}\}$, and if we assume, as we did in the continuous case, that we have some intermediate initial conditions $\{\lambda_i\}_{i=1}^{N-1}$, we can solve $F_{\Delta t}$ separately on each $I_{\Delta t}^i$: 
\begin{align*}
\left\{
     \begin{array}{lr}
		F_{\Delta t}^i(y_i(t_k),v(t_k))=0 \	\textit{For $k \in \{k_i,k_i+1,...,k_{i+1} \}$} \\
		y(t_{k_i})=\lambda_i
	\end{array}
   \right.	
\end{align*} 
There is one minor issue with decomposing $I_{\Delta t}$, which I did not mention above, and that has to do with the choice of the subsequence $\{t_{k_i}\}_{i=0}^N$. In theory, one could of course freely chose any subsequence of $I_{\Delta t}$, but we generally want the difference $t_{k_i} -t_{k_{i+1}}$ to be constant for all $i$. This is however not always possible, since there is no guarantee that $n$ is divisible by $N$.
\subsection{Partitioning}
The general rule for partitioning a task between $N$ processes, is to distribute the work of the task as evenly as possible. The task in the above setting is solving $ F_{\Delta t}$, and the work to be distributed, is the computations required to move the solution from one time step to the next for all time steps. Since there are $n$ time steps, we should be able to say that the main task of solving $F_{\Delta t}$ can be divided into $n$ subtasks, and it is these $n$ tasks that we want to distribute between the $N$ processes. Now deciding how many subtasks each process should get is quite simple. Start with defining the numbers:
\begin{align*}
q &= \lfloor \frac{n}{N}\rfloor \\
r &= N \mod n
\end{align*} 
Then we give each process $q$ tasks, and then add one task to $r$ processes. To which processes you give the extra task does not really matter, but the most straightforward way of doing it is just to give the first $r$ processes the extra task. I however chose to look at the distributing problem slightly different, by instead of trying to distribute the $n$ tasks, looking at how to evenly divide the $n+1$ points $\{t_k\}_{k=0}^{n}$ among the $N$ processes. Again lets define $q$ and $r$ as:
\begin{align*}
q &= \lfloor \frac{n+1}{N}\rfloor \\
r &= N \mod n+1
\end{align*}
Every process now gets $q$ points, but due to overlap every process gets an extra point excluding the first process. Then the remaining $r$ points are given to the first $r$ processes. This allows me to define the sequence $\{k_{i}\}_{i=0}^N$ recursively as follows:
\begin{align*}
k_{i+1} = k_i + q+\delta_{i\neq0}+\delta_{i<r}
\end{align*}
Here the $\delta$s are conditional functions defined as:
\begin{align*}
\delta_{S}=\left\{
     \begin{array}{lr}
		1 \ S=\text{True} \\
		0 \ S=\text{False}
	\end{array}
   \right.	
\end{align*} 
We now have a way of decomposing the discrete time interval, and therefore also a way of partitioning the finite difference solver of the state equation in temporal direction. However both when we want try to find the gradient in a penalized optimal control problem, or when we just want to parallelize solving a differential equation using the parareal scheme, some communication between the processes is required. 
