\documentclass[11pt,a4paper]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
 
\usepackage{cite}


\newtheorem{theorem}{Theorem}

\usepackage{listings}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}


\usepackage{graphicx}

\title{Parareal explanation}


\begin{document}
\maketitle
\section{Introduction}
Want to summarize the paper \cite{lions2001resolution}, and explain the parareal scheme. The parareal scheme is used to parallelize differential equations in temporal direction, by decomposing the time interval $I=[0,T]$. The equation looks like the following:
\begin{align}
\left\{
     \begin{array}{lr}
		\frac{\partial u}{\partial t} + Au = f \ 				\textit{For $t \in I$} \\
		u(0)=u_0
	\end{array}
   \right.			
\end{align} 
Decomposing the interval $I$, means dividing the interval into $N$ subintervals $\{I_n = [T^{n},T^{n+1}]\}_{n=0}^{N-1}$, with length $\Delta T = T/N$. We also define new equations equations for each interval:
\begin{align}
\left\{
     \begin{array}{lr}
		\frac{\partial u^n}{\partial t} + Au^n = f \ 				\textit{For $t \in I^n$} \\
		u^n(T^n)=\lambda^n
	\end{array}
\right.	
\end{align}
Here $\lambda^0=u_0$. If the $\lambda$s are known, we can solve the equations independently on each interval. The problem is that the $\lambda$s depend on the previous intervals, and need to be calculated by solving the equation. The parareal scheme is a way of dealing with this.
\section{The parareal scheme} 
The parareal scheme finds the $\lambda$s, by solving the equation on the entire interval using an implicit euler scheme on a very course resolution, and then using this numerical solution $Y$ at the decomposed interval boundaries $\{T^n\}_{n=1}^{N-1}$ as $\lambda$s, for the real solver $y$. We can then repeat this process, by propagating the jumps $S^n=y^{n-1}(T^n)-Y^n$ using the course scheme. This creates an iteration, that looks like this:
\begin{align*}
&(i) \ \textit{Set $S^n_k = y_k^{n-1}(T^n)-Y_k^n$} \\
&(ii) \ \textit{Propogate the jumps with the couarse scheme $\delta_k$ using (\ref{propagator})} \\
&(iii) \ \textit{Update $Y_{k+1}^n=y_k^{n-1} + \delta_k^n$}
\end{align*} 
\\
\\
To illustrate how it works, I will set up the parareal scheme for a simple ODE:
\begin{align}
\left\{
     \begin{array}{lr}
		\frac{\partial y}{\partial t}(t)=-ay(t) \ 				\textit{on $[0,T]$} \\
		y(0)=y_0
	\end{array}
\right.	\label{ODE_eks}
\end{align}
If we discretize (\ref{ODE_eks}) using implicit euler, we get:
\begin{align}
\left\{
     \begin{array}{lr}
		\frac{Y^{n+1}-Y^{n}}{\Delta T}+aY^{n+1}=0  \\
		Y^0=y_0
	\end{array}
\right.	\label{couarse_euler}
\end{align}
Notice that the interval $I$, is discretized using the same time difference as the time decomposition. Then we introduce $N$ new equations on each interval, i.e.
\begin{align}
\left\{
     \begin{array}{lr}
		\frac{\partial y^n}{\partial t}(t)=-ay^n(t) \ 				\textit{on $[T_n,T_{n+1}]$} \\
		y(T_n)=Y^n
	\end{array}
\right. \label{interval_eqs}
\end{align}
We can now solve (\ref{interval_eqs}) independently either exactly or using some numerical scheme. So if we first solve (\ref{couarse_euler}) and then (\ref{interval_eqs}), and define $Y_1^n=Y^n$, $y_1^n(t)=y^n(t)$, we can set an initial jump $S_1^n=y_1^{n-1}(T^n)-Y_1^n$ and start the iterative jump propagation process. Lets now specify, whet is meant by \textit{propogate the jumps with the couarse scheme}:
\begin{align}
\left\{
     \begin{array}{lr}
		\frac{\delta_k^{n+1}-Y^{n}}{\Delta T}+a\delta_k^{n+1}=\frac{S_k ^n}{\Delta T}  \\
		\delta_k^0=0
	\end{array}
\right. \label{propagator}
\end{align} 
\section{Error estimate}
According to \cite{lions2001resolution} we have the following error estimate for the parareal scheme of (\ref{ODE_eks}):
\begin{gather*}
\forall \ n,0\leq n\leq N-1 \\ |Y_k^n-y(T^n)| + \max_{t\in[T^N,T^{n+1}]}|y_k^n(t)-y(t)| \leq c_k\Delta T^k
\end{gather*} 
This suggest that the max norm difference between exact and parareal solution looks like this:
\begin{align*}
\max_{t\in[0,T]}|y_k(t)-y(t)| \leq C_k\Delta T^k
\end{align*}
The error estimate for a first order scheme, like implicit euler, we know looks like this:
\begin{align*}
\max_{t\in[0,T]}|y_{\Delta t}(t)-y(t)| \leq C\Delta t
\end{align*}
It would then be reasonable that the number of iterations for the parareal scheme needed to reach the same error as the fine first order solver, would be:
\begin{align*}
k\approx\frac{\log(\Delta t)}{\log(\Delta T)}
\end{align*}
This assumes that the constants $C_k$ and $C$ are similar. This is a reasonable assumption, since these constants depend on the parameters of the equation (\ref{ODE_eks}). 
\\
\\
To illustrate this lets try to solve a version of (\ref{ODE_eks}) using an implicit euler scheme and parareal with a fine implicit euler solver. I will use  the parameters $a=1.3$, $T=1$ and $y_0= 3.52$. The fine resolution will be held constant at $\Delta t=\frac{1}{10000}$. I then calculated how many propagation iterations I needed to to reduce the max-norm error to below $\Delta t$ for different time interval decompositions $N$. Table follows below:
 \begin{center}
    \begin{tabular}{| l | l | l | l |}
    \hline
     & $\frac{\log(\Delta t)}{\log(\Delta T)}$&iterations  & $\max_{t\in[0,T]}|y_k(t)-y(t)|$   \\ \hline
    $N=1$ &0 & 1& 8.416625e-5 	\\ \hline
    $N=2$ &13.3 &2& 8.416625e-5 	\\ \hline
    $N=5$ &5.7&4& 8.416625e-5	\\ \hline
    $N=10$ &4&4& 8.399513e-5	\\ \hline
    $N=25$ &2.8&3& 	8.737827e-5\\ \hline
    $N=100$ &2&2&	6.302522e-5\\ \hline
    \end{tabular}
\end{center}
\bibliography{ppaper}
\bibliographystyle{plain}
\end{document}