\documentclass[11pt,a4paper]{report}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{graphicx}

\usepackage{listings}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{booktabs}

\usepackage{graphicx}


\begin{document}
\section{Problem}
We are solving this problem:
\begin{gather*}
J(y,u) = \frac{1}{2}\int_0^Tu^2dt + \frac{1}{2}(y(T)-y^T)^2
\end{gather*} 
and let our ODE constraint be:
\begin{align*}
\left\{
     \begin{array}{lr}
       	E(y,u) = y'-\alpha y -u\\
       	   y(0)=y_0
     \end{array}
   \right.
\end{align*}
To do this we need the gradient of the reduced $J$, which is:
\begin{align*}
\nabla\hat{J} = u+p
\end{align*}
p is the solution of the adjoint equation:
\begin{align*}
   \left\{
     \begin{array}{lr}
       -p'(t) -\alpha p(t)=0  \\
       p(T) = y(T)-y^T
     \end{array}
   \right.
\end{align*}
Because we want to parallelize in time we also try to solve the control problem with added penalty terms:
\begin{align*}
J(y,u,\lambda) = \int_0^T u^2 dt + \frac{1}{2}(y_m(T)-y^T)^2 + \frac{\mu}{2} \sum_{i=1}^{m-1} (y_{i}(T_i)-\lambda_i)^2 
\end{align*}
This functional has the following gradient:
\begin{align*}
\hat{J}'(u,\lambda) = (u+p,p_{2}(T_1) -p_{1}(T_1),..., p_{m}(T_{m-1}) -p_{m}(T_{m-1}))
\end{align*} 
We now also solve the state equations:
\begin{align*}
   \left\{
     \begin{array}{lr}
       \frac{\partial }{\partial t} y_i(t) = \alpha y_i(t) + u(t) \ \text{for $t \in [T_{i-1},T_{i}]$}\\
	y_i(T_{i-1}) = \lambda_{i-1}
     \end{array}
   \right.
\end{align*}
and the adjoint equations:
\begin{align*}
-\frac{\partial }{\partial t}p_m &=\alpha p_m  \\
p_m(T_{m}) &= y_m(T_{m})-y_T
\end{align*}
On $[T_{i-1},T_i]$ the adjoint equation is:
\begin{align*}
-\frac{\partial }{\partial t}p_i &=p_i  \\
p_i(T_{i}) &= \mu(y_{i}(T_{i})-\lambda_{i} )
\end{align*}
\section{Assumption}
Assume that we have solved the non-penalty problem, and have an optimal control $u^*$ and a corresponding solution to the state equation $y^*$. What happens if we try to solve the same problem using the penalty method with $u*$ and $\lambda_i =y^*(T_i)$ as an initial guess? One might expect that $u*$ would also be optimal for the penalty method with any choise of $\mu$. This is however not the case, and we see why, by calculating the gradient using the initial guess. The problem is that the adjoint equation in all subintervals except the last have initial condition 0. This results what is shown in plot below. If we then solve the problem using $u^*$ as initial guess, we will eventually get a solution close to $u^*$, but it will not be exactly the same.
\\
\\
Even though $u^*$ is not a valid solution for the penalty method, using it as initial guess allows us to come arbitrary close to the real non-penalty solution if solve it using increasing $\mu$ values.
\\
\\ 
\begin{tabular}{lrr}
\toprule
{} &             $\mu$ &    $||u-u_{\mu}||_{L^2}$ \\
\midrule
0  &             10 &  3.298276e-01 \\
1  &            100 &  4.510803e-06 \\
2  &           1000 &  4.620845e-07 \\
3  &          10000 &  4.632146e-08 \\
4  &         100000 &  4.633279e-09 \\
5  &        1000000 &  4.633392e-10 \\
6  &       10000000 &  4.633403e-11 \\
7  &      100000000 &  4.633407e-12 \\
8  &     1000000000 &  4.633409e-13 \\
9  &    10000000000 &  4.632983e-14 \\
10 &   100000000000 &  4.689641e-15 \\
11 &  1000000000000 &  6.090340e-16 \\
\bottomrule
\end{tabular}
\begin{figure}
  \includegraphics[width=\linewidth]{adjoint.png}
  \caption{Due to zero difference in state equation jumps, the adjoint in the penalty case has a big jump. This jump will show up in the gradient}
  \label{Fig 1}
\end{figure}
\begin{figure}
  \includegraphics[width=\linewidth]{control.png}
  \caption{Results of non-penalty and penalty solver, when using $u^*$ as initial guess for penalty solver}
  \label{Fig 2}
\end{figure}
\end{document}