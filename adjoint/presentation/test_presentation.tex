\documentclass[9pt]{beamer}

\usepackage{color, array, threeparttable}
\setbeamerfont{page number in head/foot}{size=\large}
\setbeamertemplate{footline}[frame number]
\usepackage{amsmath,amsfonts,amssymb,amsthm, gensymb}
\DeclareMathAlphabet{\mathbbold}{U}{bbold}{m}{n}    
\setbeamertemplate{footline}[frame number]
%\usepackage{beamerthemeshadow}
\usepackage[utf8]{inputenc}
\usepackage[ruled,boxed]{algorithm2e}
\makeatletter
\newcommand*{\rom}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother
%Information to be included in the title page:
\title{A Parallel in Time Method for Optimal Control}
\subtitle{Parareal-Based preconditioner for the BFGS algorithm}
\author{Andreas Thune}
\institute[UiO]{Faculty of Mathematics \\University of Oslo}
\date{Master presentation, June 2017}
\usepackage{verbatim}
\usepackage{booktabs}
\usepackage{subcaption}

\usetheme{Madrid}
\usecolortheme{beaver}
%\usecolortheme{beetle}
\begin{document}
 
\frame{\titlepage}
%\tableofcontents
\begin{frame}
\frametitle{Contents}
\begin{block}{}
\centering
\alert{Goal}: Propose a parallel in time method for optimal control problems
\end{block}
\begin{enumerate}[I]
\item{The Parareal Algorithm}
\item{Optimal Control with ODE constraints}
\item{Optimization Algorithms}
\item{Presentation of Parareal Preconditioned Parallel in Time Method}
\item{Experiments}
\end{enumerate}
\end{frame}
\section{Parareal}
\begin{frame}
\frametitle{The Parareal Algorithm \rom{1}}
\begin{columns}
\column{0.48\linewidth}
\begin{itemize}
\item{The Parareal algorithm was introduced in [Lion et al] as a way of parallelizing time-dependent PDEs $f(y(t),t)=0$ in temporal direction.}
\item{The Parareal algorithm combines a coarse and a fine numerical scheme for a discretization in time. The fine scheme is run in parallel, while the coarse scheme is run serially.}
\item{If we let $\bold{F}_{\Delta T}$ and $\bold{G}_{\Delta T}$ be the fine and coarse propagators that evolve the equation from $\lambda$ at time $t$ to $y(t+\Delta T)$.}
\end{itemize}
\column{0.48\linewidth}
\begin{figure}
\includegraphics[scale=0.2]{parareal.png}
\caption{{\small 
The intermediate initial conditions $\{\lambda_i\}_{i=1}^{19}$ are found using a coarse solve. The fine scheme is then applied independently on each subinterval with the $\lambda_i$'s as initial conditions.
}}
\end{figure}
\end{columns}
\end{frame}
\begin{frame}
\frametitle{The Parareal Algorithm \rom{2}}
\begin{columns}
\column{0.58\linewidth}
\begin{itemize}
\item{The predictor correction formulation of the Parareal algorithm is defined through th following iteration:
{\small \begin{align*}
\lambda_{i+1}^{k+1} &= \bold{G}_{\Delta T}(\lambda_{i}^{k+1})+\bold{F}_{\Delta T}(\lambda_{i}^{k})-\bold{G}_{\Delta T}(\lambda_{i}^{k}) \\
\lambda_0^k&=y_0,\quad \lambda_{i+1}^0 = \bold{G}_{\Delta T}(\lambda_{i}^{0})
\end{align*}}}
\item{In [Maday et al] the authors show that the Parareal iteration also can be written on matrix form as:
{\small \begin{align*}
\Lambda^{k+1} = \Lambda^k -\bar M^{-1}(M\Lambda-h).
\end{align*}}
Here $\Lambda=\{\lambda_i\}_{i=0}^{N-1}$, $h=(y_0,0,...,0)^T$ and
{\tiny\begin{align*}
M = \left[ \begin{array}{cccc}
   \mathbbold{1} & 0 & \cdots & 0 \\  
   -\bold{F}_{\Delta T} & \mathbbold{1} & 0 & \cdots \\ 
   0 &-\bold{F}_{\Delta T} & \mathbbold{1}  & \cdots \\
   0 &\cdots &-\bold{F}_{\Delta T} & \mathbbold{1}  \\
   \end{array}  \right]\in\mathbbold{R}^{N\times N}.
\end{align*}} }
\end{itemize}
\column{0.38\linewidth}
\begin{figure}
\includegraphics[scale=0.4]{parareal2.png}
\caption{Insert caption}
\end{figure}
\end{columns}
\end{frame}
\section{Problem}
\begin{frame}
\frametitle{Optimization with ODE Constraints}
\begin{itemize}
\item{The focus of this thesis have been ODE constrained optimization problems.}
\item{The goal of such problems is to find the state and control $(y,v)$ that minimizes the objective function $J$, while simultaneously satisfying the state equation $E(y,v)=0$.}
\end{itemize}
\begin{block}{Optimal Control Problem}
\begin{align*}
\min_{y,v} &J(y(t),v), \\
\textrm{subject to} \ &E(y(t),v)=0,\quad t\in[0,T].
\end{align*}
\end{block}
\end{frame}
\begin{frame}
\frametitle{The Reduced Problem}
\begin{itemize}
\item{If the State equation is well posed for all control variables $v\in V$, we can define a reduced objective function $\hat{J}(v) = J(y(v),v)$.}
\item{Using $\hat J$, we can transform the optimal control problem into an unconstrained optimization problem.}
\end{itemize}
\begin{align*}
\min_{v\in V}\hat J (v)
\end{align*}
\begin{itemize}
\item{Evaluating $\hat J(v)$ requires us to first solve the state equation for the control $v$.}
\item{Since the reduced problem is unconstrained, we can use methods from unconstrained optimization to solve it. Such methods utilize the first order optimality condition $\hat J'(v)=0$, and we therefore need a way to evaluate the gradient of the reduced objective function.}
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Adjoint Approach to Gradient Evaluation}
\begin{itemize}
\item{If $E$ and $J$ are sufficiently smooth, and $E_y$ is continuously invertible, the gradient of the reduced objective function $\hat J'(v)$ exists.}
\item{We can show that the gradient of the objective function is $\hat J'(v)=E_v(y(v),v)^*p +J_v(y(v),v)$. }
\item{$p$ is here the solution of the adjoint equation $E_y(y(v),v)^*p = J_y(y(v),v)$.}
\item{Evaluating $\hat J'$ for a control $v$ then comes down to the following three steps:
\begin{description}
\item[1.]{Solve the state equation $E(y,v)=0$ for $y$.}
\item[2.]{Solve the adjoint equation $E_y(y(v),v)^*p = J_y(y(v),v)$ for $p$.}
\item[3.]{Instert $y$ and $p$ into $J'(v)=E_v(y(v),v)^*p +J_v(y(v),v)$.}
\end{description}}
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Example Problem}
\begin{columns}
\column{0.58\linewidth}
\begin{block}{Example Problem}
\begin{align*}
&J(y,v) = \frac{1}{2}\int_0^Tv(t)^2dt + \frac{\alpha}{2}(y(T)-y^T)^2 \\
&\left\{
     \begin{array}{lr}
       	y'(t)=ay(t) + v(t), \quad  t\in(0,T),\\
       	y(0)=y_0.
     \end{array}
   \right. 
\end{align*}
\end{block}
\begin{itemize}
\item{{\small The adjoint equation of the example problem is:}
{\small
\begin{align*}
\left\{
     \begin{array}{lr}
       	p'(t)=-ap(t), \quad  t\in(0,T),\\
       	p(T)=\alpha(y(T)-y^T).
     \end{array}
   \right. 
\end{align*}
}}
\item{{\small The gradient of the example objective function is:}{\small
\begin{align*}
\hat{J}'(v) = v+p
\end{align*}
}}
\item{{\small The exact solution of the example problem is:}
{\small 
\begin{align*}
v(t) = \alpha\frac{e^{aT}(y^T-e^{aT}y_0)}{1+\frac{\alpha e^{aT}}{2a}(e^{aT}-e^{-aT})}e^{-at}
\end{align*}}}
\end{itemize}
\column{0.38\linewidth}
\begin{figure}
%\centering
\includegraphics[scale=0.24]{ype.png}
\caption{{\tiny The state and adjoint equation of the example problem with parameters $(a,y_0,y^T,T)=(-3,5,-7,1)$, and control variable $v(t)=10\cos(5\pi t)$.}}
\end{figure}
\end{columns}
\end{frame}
\begin{frame}
\frametitle{Discretization}
\end{frame}
%llllllllllllllllllllllllllllllllllllllllllllllll
\section{optimization}
\begin{frame}
\frametitle{Line Search Methods}
\begin{columns}
\column{0.58\linewidth}
\begin{itemize}
\item{Iterative methods for unconstrained optimization.}
\item{Produces iterates $\{x^k\}$, utilizing an initial guess $x^0$.}
\item{One iteration of a line search method:}
{\small
\begin{align*}
1.\quad& \textrm{Find descent direction $p^k$}\\
2.\quad& \textrm{Find an adequate step length $\gamma^k$}\\
3.\quad& \textrm{Update iterate $x^{k+1} = x^k -\gamma^k p^k$}
\end{align*}
}%
\item{The steepest descent method, where $p^k=f(x^k)$, and Newtons method, where $p^k =f''(x^k)^{-1}f'(x^k)$, are examples of line search methods. }
\end{itemize}
\column{0.38\linewidth}
\begin{figure}[!h]
\centering
\includegraphics[scale=0.3,angle=90]{SD.png}
\caption{Illustration of the steepest descent algorithm from [Nocedal et al]}
\end{figure}
\end{columns}
\end{frame}
\begin{frame}
\frametitle{BFGS}
\begin{columns}
\column{0.48\linewidth}
\begin{itemize}
\item{Quasi-Newton are line search methods with $p^k=H^kf'(x^k)$, where $H^k\approx f''(x^k)^{-1}$.}
\item{The BFGS algorithm approximates $f''(x^k)^{-1}$ using information from previous iterates. The $H^k$'s are constructed so that they are symmetric and positive definite. To guarantee this, the initial inverted Hessian approximation $H^0$ must also possess these properties.}
\item{After each iteration $H^k$ is updated using the following formula:}
{\tiny
\begin{align*}
H^{k+1} &= (\mathbbold{1}-\rho_kS_k^T Y_k)H^k(\mathbbold{1} -\rho_kY_k^T S_k) + S_k^T S_k\\
S_k &= x^{k+1}-x^{k},
\quad Y_k = \nabla f(x^{k+1})-\nabla f(x^{k}),\\
\rho_k &= \frac{1}{Y_k^T S_k}.
\end{align*}
}%
\end{itemize}
\column{0.38\linewidth}
{\small
\begin{algorithm}[H] 
\KwData{Choose an initial guess $x^0$ and a tolerance $\tau$}
\While{$||\nabla f(x^k)||\geq \tau$ }{
$x^{k+1} \leftarrow x^k - \gamma^k H^k \nabla f(x^k)$\;
Update $H^{k+1}$\;
}
\caption{The BFGS method\label{SEQ_ALG}}
\end{algorithm}
}
\end{columns}
\end{frame}
%llllllllllllllllllllllllllllllllllllllllllllllll
\section{PPC}
\begin{frame}
\frametitle{Decomposed Problem}
\begin{itemize}
\item{We let $0=T_0<T_1<\cdots<T_{N-1}<T_N=T$, and decompose $[0,T]$ into $N$ subintervals $[T_{i-1},T_i]$. }
\item{We introduce intermediate initial values $\Lambda=(\lambda_1,...,\lambda_{N-1})$, and decompose the state equation into $N$ equations $E^i(y_i,v,\lambda_{i-1})=0$ defined separately on each interval $[T_{i-1},T_i]$.}
\item{To enforce continuity of the decomposed state, we introduce extra constraints $y_i(T_i)=y_{i+1}(T_i)$.}
\end{itemize}
\begin{block}{Decomposed and reduced optimal control problem}
\begin{align*}
\min_{v,\Lambda} &\hat J(v,\Lambda), \\
\textrm{subject to} \ &y_i(T_i)=\lambda_i,i=1,...,N-1. 
\end{align*}
\end{block}
\end{frame}
\begin{frame}
\frametitle{Quadratic Penalty Method \rom{1}}
\begin{itemize}
\item{Consider the constrained optimization problem:
\begin{align*}
\min_x f(x) \quad \textrm{subject to} \ c_i(x)=0 \quad i=1,...,N
\end{align*}}
\item{The quadratic penalty method is a method for solving constrained problems. The idea is to move the constraints into the functional:
\begin{align*}
f_{\mu}(x) = f(x) + \frac{\mu }{2}\sum_{i=1}^N c_i(x)^2, \quad \mu>0.
\end{align*}}
\item{For large $\mu$ values the minimizer of $f_{\mu}$ approximates the minimizer of $f$.}
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Quadratic Penalty Method \rom{2}}
\begin{columns}
\column{0.48\linewidth}
\begin{itemize}
\item{The penalized objective function for the decomposed optimal control problem is {\tiny
\begin{align*}
\hat{J}_{\mu}(v,\Lambda) = \hat{J}(v) + \frac{\mu}{2}\sum_{i=1}^{N-1}(y_{i}(T_i)-\lambda_i)^2
\end{align*}}}
\item{Using the adjoint approach we can find the gradient of the penalized objective function: {\tiny
\begin{align*}
\hat J_{\mu}'(v,\Lambda) = (v+p,\{p_{i+1}(T_i)-p_{i}(T_i)\}_{i=1}^{N-1})
\end{align*}}}
\item{When we decompose the time domain and state equation, the adjoint equation is also defined independently on each subinterval.}
\end{itemize}
\column{0.48\linewidth}
{\tiny
\begin{algorithm}[H] 
\KwData{Choose $\mu_0,\tau_0>0$, and some initial control $(v^0,\Lambda^0$)}
\For{$k=1,2,...$}{
Find $(v^k,\Lambda^k)$ s.t. $\parallel\nabla \hat J_{\mu_{k-1}}(v^k,\Lambda^k)\parallel<\tau_{k-1}$\;
\eIf{STOP CRITERION satisfied}{
$\bold{Stop}$ algorithm\;
}{
Choose new $\tau_k\in(0,\tau_{k-1})$ and $\mu_k\in(\mu_{k-1},\infty) $\;
}
}
\caption{Penalty method\label{PEN_ALG}}
\end{algorithm}}%
\begin{itemize}
\item{If for all $k$, the pair $\{(v^k,\Lambda^k)\}$ from algorithm \ref{PEN_ALG} is the exact global minimizer of $\hat J_{\mu_k}$, $\{(v^k,\Lambda^k)\}$ will converge towards the minimizer of $\hat J$.}
\end{itemize}
\end{columns}
\end{frame}
\begin{frame}
\frametitle{Parareal-Based Preconditioner}
\begin{itemize}
\item{We minimize $\hat J_{\mu_k}$ using the BFGS method. {\small
\begin{align*}
(v_{j+1}^{k},\Lambda_{j+1}^{k}) = (v_j^k,\Lambda_j^k) - \rho_jH_j \hat J'(v_j^k,\Lambda_j^k)
\end{align*}}}
\item{We want to use the preconditioner proposed in [Maday et al] in the BFGS method. We do this by setting $H_0=Q$, where $Q$ is: {\small
\begin{align*}
Q = \left[ \begin{array}{cc}
	\mathbbold{1} & 0 \\
	0 & Q_{\Lambda} \\
	\end{array} \right]\in \mathbb{R}^{n_v+N-1\times n_v+N-1},\quad Q_{\Lambda}\in\mathbb{R}^{N-1\times N-1}
\end{align*}}}
\item{We derive and motivate what $Q_{\Lambda}$ is by considering the virtual problem.}
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Virtual Problem \rom{1}}
\begin{itemize}
\item{The virtual problem is the ODE constrained optimization problem where the control variable is only the virtual control:
{\tiny
\begin{align*}
\bold{ \hat J}(\Lambda) = \frac{1}{2} x(\Lambda)^Tx(\Lambda),\quad
x(\Lambda)=\left( \begin{array}{c}  
   \lambda_1 - \bold F_{\Delta T}(y_0) \\ 
   \lambda_2 - \bold F_{\Delta T}(\lambda_1) \\
   \cdots  \\
   \lambda_{N-1} -\bold F_{\Delta T}(\lambda_{N-1}) \\
   \end{array}  \right).
\end{align*}}}
\item{The gradient of the virtual objective function is:
{\tiny
\begin{align*}
\nabla \bold{\hat J}(\Lambda)= \nabla x(\Lambda)^T x(\Lambda) = M(\Lambda)^Tx(\Lambda),
\end{align*}}
where 
{\tiny
\begin{align*}
M(\Lambda)= \left[ \begin{array}{cccc}
   \mathbbold{1} & 0 & \cdots & 0 \\  
   -\bold{F}_{\Delta T}'(\lambda_{1}) & \mathbbold{1} & 0 & \cdots \\ 
   0 &-\bold{F}_{\Delta T}'(\lambda_{2}) & \mathbbold{1}  & \cdots \\
   0 &\cdots &-\bold{F}_{\Delta T}'(\lambda_{N-1}) & \mathbbold{1}  \\
   \end{array}  \right]
\end{align*}}}
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Virtual Problem \rom{2}}
\begin{itemize}
\item{The Hessian of the virtual objective function is:
{\small
\begin{align*}
\nabla^2 \bold{\hat J}(\Lambda)= \nabla x(\Lambda)^T \nabla x(\Lambda) + \nabla^2 x(\Lambda)^Tx(\Lambda) = M(\Lambda)^TM(\Lambda) + D(\Lambda),
\end{align*}}
where {\tiny$D(\Lambda)$} is a diagonal matrix with entries {\tiny$D_i=-\bold{F}_{\Delta T}''(\lambda_i)(\lambda_{i+1}-\bold F_{\Delta T}(\lambda_i))$}.}
\item{If the governing equation of {\tiny$\bold F_{\Delta T}$} is linear, {\tiny$D(\Lambda)=0$}, which means that {\tiny$\nabla^2 \bold{\hat J}(\Lambda)= M(\Lambda)^TM(\Lambda)$}.}
\item{The idea now is to base the preconditioner $Q_{\Lambda}$ on an approximation of the inverse of {\tiny$M(\Lambda)^TM(\Lambda)$}. This is done by utilizing a coarse propagator {\tiny$\bold{G}_{\Delta T}$}, and defining a coarse version of $M(\Lambda)$.
{\tiny
\begin{align*}
\bar M(\Lambda)= \left[ \begin{array}{cccc}
   \mathbbold{1} & 0 & \cdots & 0 \\  
   -\bold{G}_{\Delta T}'(\lambda_{1}) & \mathbbold{1} & 0 & \cdots \\ 
   0 &-\bold{G}_{\Delta T}'(\lambda_{2}) & \mathbbold{1}  & \cdots \\
   0 &\cdots &-\bold{G}_{\Delta T}'(\lambda_{N-1}) & \mathbbold{1}  \\
   \end{array}  \right]
\end{align*}}}
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Properties of $\bar M(\Lambda)^T\bar M(\Lambda)$}
\begin{columns}
\column{0.48\linewidth}
\begin{itemize}
\item{The inverse of $\bar M(\Lambda)$ is a linearised forward solve, while the inverse of $\bar M^T(\Lambda)$ is a linearised backwards solve.}
\item{$\bar M(\Lambda)^T\bar M(\Lambda)$ is symmetric positive definite.}
\item{For $N=2$ decompositions of the time domain $Q=\mathbbold{1}$.}
\item{Applying $Q$ is an $\mathcal{O}(N)$ operation.}
\end{itemize}
\column{0.58\linewidth}
\centering
\begin{figure}[!h]
\centering
\includegraphics[scale=0.24]{apply.png}
\end{figure}
\end{columns}
\end{frame}
\begin{comment}
{\tiny
Applying $\bar M(\Lambda)^{-1}\bar M(\Lambda)^{-T}\in \mathbbold{R}^{3\times 3}$ to a vector $(x_1,x_2,x_3)$:
\begin{align*}
1.\quad &\textrm{Apply $\bar M(\Lambda)^{-T}$ to $x$:} \\
&\bar M(\Lambda)^{-T}x= \left(\begin{array}{c}
x_1 + \bold G_{\Delta T}'(\lambda_1)(x_2 + \bold G_{\Delta T}'(\lambda_2)x_3)\\
x_2 + \bold G_{\Delta T}'(\lambda_2)x_3 \\
x_3 \\
\end{array}
\right) 
\\
2.\quad &\textrm{Apply $\bar M(\Lambda)^{-1}$ to $y=\bar M(\Lambda)^{-T}x$:} \\
&\bar M(\Lambda)^{-1}y = \left(\begin{array}{c}
y_1 \\
y_2 + \bold G_{\Delta T}'(\lambda_1)y_1 \\
y_3 + \bold G_{\Delta T}'(\lambda_2)(y_2 + \bold G_{\Delta T}'(\lambda_1)y_1)\\
\end{array}
\right)
\end{align*}}
\end{comment}
\begin{comment}
\begin{frame}
\centering
Applying $\bar M(\Lambda)^{-1}\bar M(\Lambda)^{-T}\in \mathbbold{R}^{3\times 3}$ to a vector $(x_1,x_2,x_3)$:
\begin{align*}
1.\quad &\textrm{Apply $\bar M(\Lambda)^{-T}$ to $x$:} \\
&\bar M(\Lambda)^{-T}x= \left(\begin{array}{c}
x_1 + \bold G_{\Delta T}'(\lambda_1)(x_2 + \bold G_{\Delta T}'(\lambda_2)x_3)\\
x_2 + \bold G_{\Delta T}'(\lambda_2)x_3 \\
x_3 \\
\end{array}
\right) 
\\
2.\quad &\textrm{Apply $\bar M(\Lambda)^{-1}$ to $y=\bar M(\Lambda)^{-T}x$:} \\
&\bar M(\Lambda)^{-1}y = \left(\begin{array}{c}
y_1 \\
y_2 + \bold G_{\Delta T}'(\lambda_1)y_1 \\
y_3 + \bold G_{\Delta T}'(\lambda_2)(y_2 + \bold G_{\Delta T}'(\lambda_1)y_1)\\
\end{array}
\right)
\end{align*}
\end{frame}
\end{comment}
\begin{frame}
\frametitle{Parallel in Time Algorithm for Optimal Control}
\begin{itemize}
\item{Complete parallel in time algorithm based on Parareal-preconditioned BFGS solver.}
\end{itemize}
{\tiny
\begin{algorithm}[H] 
\KwData{Choose $\mu_0,\tau_0>0$, and some initial control $(v^0,\Lambda^0$)}
\For{$k=1,2,...$}{
$(v_0^k,\Lambda_0^k) \leftarrow (v^{k-1},\Lambda^{k-1})$\;
$H^0 \leftarrow Q(\Lambda_0^{k})$\;
\While{$||\hat J'_{\mu_{k-1}}(v_j^k,\Lambda_j^k)||\geq \tau_{k-1}$ }{
$(v_{j+1}^k,\Lambda_{j+1}^k) \leftarrow (v_j^k,\Lambda_j^k) - \rho^j H^j \hat J'_{\mu_{k-1}}(v_j^k,\Lambda_j^k) $\tcp*[h]{In parallel}\;
Update $H^{j+1}$\;
$H^0 \leftarrow Q(\Lambda_{j+1}^k)$\;
}
$(v^{k},\Lambda^{k})\leftarrow(v_{j}^k,\Lambda_{j}^k)$\;
\eIf{STOP CRITERION on $(v^{k},\Lambda^{k})$ satisfied}{
$\bold{Stop}$ algorithm\;
}{
Choose new $\tau_k\in(0,\tau_{k-1})$ and $\mu_k\in(\mu_{k-1},\infty) $\;
}
}
\caption{Quadratic penalty method with preconditioned BFGS optimization\label{PPC_PEN_ALG}}
\end{algorithm}
}
\end{frame}

\begin{frame}
\frametitle{Computational Cost of Objective Function and Gradient Evaluation}
\begin{itemize}
\item{Evaluating the objective function requires one state equation solve, while we to evaluate the gradient need to solve both the state and adjoint equations.}
\item{When decomposing the time domain, we expect the runtime of objective function and gradient evaluation to be in a order of $\mathcal{O}(\frac{n}{N})$. We verified for the example problem, and selected results are presented in the table below. }
\end{itemize}
\begin{table}[!h]
\centering
\begin{tabular}{lrrrr}
\toprule
{}$N$ &  functional time (s) &  gradient time (s) &  functional speedup &  gradient speedup \\
\midrule
1 &           8.350 &         14.930 &            1.000 &          1.000 \\
3 &           2.932 &          5.033 &            2.847 &          2.966 \\
5 &           1.796 &          3.089 &            4.647 &          4.833 \\
\bottomrule
\end{tabular}
\end{table}
\end{frame}
%llllllllllllllllllllllllllllllllllllllllllllllllll
\section{consistency}
\begin{frame}
\frametitle{Consistency}
\begin{columns}
\column{0.48\linewidth}
\begin{itemize}
\item{To investigate the consistency of our method we compare the numerical solution of the penalized and unpenalized optimal control problem.}
\item{We observe that the minimizer of the penalized problem converge toward the minimizer of the unpenalized problem when the penalty parameter $\mu$ is increased.}
\end{itemize}
\column{0.48\linewidth}
\begin{figure}[!h]
\centering
\includegraphics[scale=0.3]{con2.png}
\caption{Results of solving example problem with parameters $(y_0,a,y^T,T,\Delta t)=(3.2,-1,11.5,1,10^{-2})$. }
\end{figure}
\end{columns}
\end{frame}
%llllllllllllllllllllllllllllllllllllllllllllllllll
\section{Experiments}
\begin{frame}
\frametitle{Experimental Setup}
\begin{columns}
\column{0.58\linewidth}
\begin{block}{Test Problem}
We investigate our algorithm using the below defined problem with $T=100$
{\small\begin{align*}
&J(y,v) = \frac{1}{2}\int_0^{T}v(t)^2dt + \frac{1}{2}(y(T)-11.5)^2, \\
&\left\{
     \begin{array}{lr}
       	y'(t)=-0.097y(t) + v(t) \quad t\in(0,T)\\
       	y(0)=3.2
     \end{array}
   \right. 
\end{align*}}
\end{block}
\begin{itemize}
\item<1->{Define $L_S$ and $L_{p_N}$ as total number of function and gradient evaluations for the serial and parallel algorithms}
\item<1->{Ideal speedup $\hat{S}=\frac{N L_S}{L_{p_N}}$}
\item<1->{$\mu$, $N$ and $n$}
\end{itemize}
\column{0.38\linewidth}
\begin{figure}
\includegraphics[scale=0.25]{exact.png}
\caption{The exact solution of the test problem.}
\end{figure}
\end{columns}
\end{frame}
\begin{frame}
\frametitle{Performance for Increasing $N$}
\begin{itemize}
\item{Test example problem for fixed problem size $n=10^3$ and penalty parameter $\mu=10^4$ for increasing number of decompositions of the time domain $N$.}
\item{We compare the preconditioned and unpreconditioned solver, using number of function and gradient evaluations ($L_{p_N}$), control variable error ($||v_e-v||$) and ideal speedup ($\hat{S}$).}
\end{itemize}
\begin{table}[h]
\centering
\begin{tabular}{lrrllrr}
\toprule
{}$N$ &  pc $L_{p_N}$ &  non-pc $L_{p_N}$ &       $||v_e-v_{pc}||$ &  $||v_e-v||$  &  pc $\hat{S}$ &  non-pc $\hat{S}$ \\
\midrule
1   &     13 &      13 &  0.000040 &    0.000040 &    1.00 &        1.00 \\
8   &     53 &      53 &  0.000483 &    0.001725 &    1.96 &        1.96 \\
16  &    109 &     175 &  0.001612 &    0.004105 &    1.90 &        1.18 \\
64  &     43 &     469 &  0.001621 &    0.017026 &   19.34 &        1.77 \\
\bottomrule
\end{tabular}
\end{table}
\end{frame}
\begin{frame}
\frametitle{Performance for Increasing $\mu$}
\begin{itemize}
\item{We now test the algorithm on the example problem for a fixed number of decompositions $N=16$ and number of time-steps $n=10^4$, while the penalty parameter $\mu$ is increased.}
\end{itemize}
\begin{table}
\centering
\begin{tabular}{lrrrrrr}
\toprule
{} $\mu$&    pc $L_{p_{16}}$ & non-pc $L_{p_{16}}$  &  pc $\hat S$ & non-pc $\hat S$ &  $||v_e-v_{pc}||$ &      $||v_e-v||$\\
\midrule
1e+2   &   99 &  357 &  3.71 &  1.03 &  6.5e-4 &   6.5e-4\\
1e+3  &  153 &  885 &  2.40 &  0.41 &  3.1e-5 &  1.1e-4 \\
1e+5 &  155 &  379 &  2.37 &  0.97 &  3.9e-5 &  9.2e-5 \\
1e+08 &  410 &  3007 &  0.89 &  0.12 &  3.9e-5 &  4.3-2 \\
\bottomrule
\end{tabular}
\end{table}
\begin{columns}
\column{0.49\linewidth}
\begin{itemize}
\item<2->{We can improve the results by doing two penalty iterations.}
\end{itemize}
\column{0.49\linewidth}
\onslide<2->{\begin{table}[h!]
\begin{tabular}{lrrr}
\toprule
{} $\mu$ & $L_{p_{16}}$ & $\hat S$ & $||v_e-v_{pc}||$ \\
\midrule
1e+5 &155 &2.37 &3.85e-5\\
1e+8 &25 &14.72 &3.87e-5\\
\midrule
Overall result &180 &2.04 &3.87e-5\\
\bottomrule
\end{tabular}
\end{table}}
\end{columns}
\end{frame}
\begin{frame}
\frametitle{Results for Unsimulated Parallelism \rom{1}}
\begin{itemize}
\item{We tested our algorithm on the Abel computer cluster to investigate if our implementation is able to achieve actual speedup.}
\item{We ran the test problem for three different problem sizes $n$, and for several different decompositions of the time domain $N$.}
\end{itemize}
\begin{figure}[!h]
\centering
\includegraphics[scale=0.3]{fspeed_fig.png}
\caption{Measured speedup, efficiency, error and $L_{p_N}$ for the three problem sizes. }
\end{figure}
\end{frame}
\begin{frame}
\frametitle{Results for Unsimulated Parallelism \rom{2}}
\begin{columns}
\column{0.48\linewidth}
\begin{itemize}
\item{When we compare the ideal speedup $\hat S$ with actual achieved speedup $S$ we observe that the actual speedup is lower than the ideal speedup. We also notice that disparity between $S$ and $\hat S$ grows as $N$ becomes larger.}
\item{The reason for the difference between $S$ and $\hat S$ is parallel overhead}
\end{itemize}
\column{0.48\linewidth}
\begin{figure}
\centering
\begin{subfigure}{1\linewidth}
\centering
\includegraphics[scale=0.2]{SS.png}
\end{subfigure}
\\
\begin{subfigure}{1\linewidth}
\includegraphics[scale=0.2]{SS2.png}
\end{subfigure}
\end{figure}
\end{columns}
\end{frame}
\begin{frame}
\frametitle{Concluding Remarks}
\end{frame}
\end{document}

